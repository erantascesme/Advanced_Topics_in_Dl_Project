{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WMGxrvUtebT"
   },
   "source": [
    "<center><br><font size=6>Final Project</font><br>\n",
    "<font size=5>Advanced Topics in Deep Learning</font><br>\n",
    "<b><font size=4>Part B</font></b>\n",
    "<br><font size=4>Load Final Models</font><br><br>\n",
    "Authors: Ido Rappaport & Eran Tascesme\n",
    "</font></center>\n",
    "\n",
    "**Submission Details:**\n",
    "<font size=2>\n",
    "<br>Ido Rappaport, ID: 322891623\n",
    "<br>Eran Tascesme , ID: 205708720 </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGFqouBeRlMB"
   },
   "source": [
    "**Import libraries**\n",
    "\n",
    "❗Note the versions of the packages, we have included information in requirements.txt❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "54mTHFBatr6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eran\\anaconda3\\envs\\DeepL\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Eran\\anaconda3\\envs\\DeepL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    normalized_mutual_info_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from peft import PeftModel\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl6qqnn4t08m"
   },
   "source": [
    "**Load CSV Files**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jP_yVbtqt0ge"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "path_dir = \"final_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbTCmSkBR8pG"
   },
   "source": [
    "**Load Models**\n",
    "\n",
    "Load the models and create a list containing all of them. Each model type has its own specific loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qtMCuQH5SAa6"
   },
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Et3zl8yqSDka"
   },
   "outputs": [],
   "source": [
    "# function that load the Base Models who trained by exc4 and exc5 without compression (kivutz)\n",
    "def load_base_model(model_name, base_weights_path):\n",
    "\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "  )\n",
    "  state_dict = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "  model.load_state_dict(state_dict)\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  return model, tokenizer\n",
    "\n",
    "\n",
    "# function that load the pruned and distilled models\n",
    "def load_compressed_model(save_model_path, device=\"cpu\"):\n",
    "    model_path = os.path.join(save_model_path, \"model.pt\")\n",
    "    model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# function that load the quantized models\n",
    "def load_quantized_model(model_name, quantized_model_path):\n",
    "  q_state_path = os.path.join(quantized_model_path, \"model.pt\")\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  # Rebuild the same base architecture\n",
    "  loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "  )\n",
    "\n",
    "  # Apply the same dynamic quantization to convert Linear -> quantized Linear\n",
    "  loaded_model = torch.quantization.quantize_dynamic(\n",
    "      loaded_model, {nn.Linear}, dtype=torch.qint8\n",
    "  )\n",
    "\n",
    "  # Now load the quantized weights (keys will match)\n",
    "  loaded_model.load_state_dict(torch.load(q_state_path, map_location=\"cpu\"))\n",
    "  loaded_model.eval()\n",
    "\n",
    "  return loaded_model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8r4ybVoSGvP"
   },
   "source": [
    "**Base Models**\n",
    "\n",
    "The models who trained by exc4 and exc5 without compression (kivutz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5-oYRjbSERD",
    "outputId": "d5ace12a-0737-4888-c015-75f292d485f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "base_weights_path = \"final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"roberta_sentiment_exc4\", model, tokenizer))\n",
    "\n",
    "base_weights_path = \"final_models/roberta_sentiment_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"roberta_sentiment_exc5\", model, tokenizer))\n",
    "\n",
    "# distilbert\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "base_weights_path = \"final_models/distilbert_exc4_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"distilbert_exc4\", model, tokenizer))\n",
    "\n",
    "base_weights_path = \"final_models/distilbert_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"distilbert_exc5\", model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6iZ_TPMSKtf"
   },
   "source": [
    "**Pruned & Distilled Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2dvplpWxSL94"
   },
   "outputs": [],
   "source": [
    "models_pathes = [\"roberta_exc4_pruned\", \"roberta_pruned\", \"distilbert_exc4_pruned\", \"distilbert_pruned\",\n",
    "                 \"distilroberta_exc4-base\", \"distilroberta-base\", \"tinybert_exc4\", \"tinybert\"]\n",
    "\n",
    "\n",
    "for model_path in models_pathes:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "    model, tokenizer = load_compressed_model(save_model_path, device=\"cpu\")\n",
    "\n",
    "    model_list.append((model_path, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIF65gxTSMU0"
   },
   "source": [
    "**Quantized Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbdVBpBOSMo9",
    "outputId": "bf9bb326-458e-4714-e0a8-93767cf584fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "models_pathes = [\"roberta_sentiment_exc4_quantized\", \"roberta_sentiment_quantized\"]\n",
    "\n",
    "for model_path in models_pathes:\n",
    "  quantized_model_path = os.path.join(path_dir, model_path)\n",
    "  model, tokenizer = load_quantized_model(model_name, quantized_model_path)\n",
    "\n",
    "  model_list.append((model_path, model, tokenizer))\n",
    "\n",
    "#distilbert\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "models_pathes = [\"distilbert_exc4_quantized\", \"distilbert_quantized\"]\n",
    "\n",
    "for model_path in models_pathes:\n",
    "  quantized_model_path = os.path.join(path_dir, model_path)\n",
    "  model, tokenizer = load_quantized_model(model_name, quantized_model_path)\n",
    "\n",
    "  model_list.append((model_path, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg5ypT99d0Up"
   },
   "source": [
    "**LoRA Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bey1qE7ed0Dk",
    "outputId": "adcbf1d3-4690-466c-a1cd-e00bf188bbfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "lora_list = [\"roberta_sentiment_exc4_LoRA\", \"roberta_sentiment_exc5_LoRA\"]\n",
    "\n",
    "for model_path in lora_list:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "\n",
    "    base_model_reload = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "    lora_model_reload = PeftModel.from_pretrained(base_model_reload, save_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "\n",
    "    model_list.append((model_path, lora_model_reload, tokenizer))\n",
    "\n",
    "\n",
    "#distilbert\n",
    "lora_list = [\"distilbert_exc4_LoRA\", \"distilbert_exc5_LoRA\"]\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "for model_path in lora_list:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "\n",
    "    base_model_reload = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "    lora_model_reload = PeftModel.from_pretrained(base_model_reload, save_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "\n",
    "    model_list.append((model_path, lora_model_reload, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Plho-VSSRDc"
   },
   "source": [
    "**Evaluation**\n",
    "\n",
    "Evaluate all models and calculate a final score for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T0k6lhmJSRVu"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_metrics(model, tokenizer, test_data, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Compute metrics for a single model on test data.\"\"\"\n",
    "    # check if the model is quantized and move it to the cpu/gpu .\n",
    "    is_quantized = any(\n",
    "        isinstance(m, nn.quantized.dynamic.Linear) or isinstance(m, nn.quantized.Linear)\n",
    "        for m in model.modules()\n",
    "    )\n",
    "    if is_quantized:\n",
    "      device = \"cpu\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # store the texts and labels\n",
    "    texts = test_data['text'].tolist()\n",
    "    labels = torch.tensor(test_data['label'].tolist()).to(device)\n",
    "\n",
    "    # start calculate the metrics. time, acc, f1, num_parmas and more.\n",
    "    start_time = time.time()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = [str(t) for t in texts[i:i+batch_size]]\n",
    "            encodings = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "            outputs = model(**encodings)\n",
    "\n",
    "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())    # store the preds\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    accuracy = accuracy_score(labels.cpu().numpy(), all_preds)\n",
    "    f1 = f1_score(labels.cpu().numpy(), all_preds, average='macro')\n",
    "\n",
    "    mcc = matthews_corrcoef(labels.cpu().numpy(), all_preds)\n",
    "    nit = normalized_mutual_info_score(labels.cpu().numpy(), all_preds)\n",
    "\n",
    "    conf_matrix = confusion_matrix(labels.cpu().numpy(), all_preds)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    nonzero_params = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'nit': nit,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'runtime_sec': runtime,\n",
    "        'total_params': total_params,\n",
    "        'nonzero_params': nonzero_params\n",
    "    }\n",
    "\n",
    "def evaluate_and_score_models(model_list, test_data, weights=None, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluate multiple HuggingFace models and compute a relative weighted score.\n",
    "\n",
    "    Args:\n",
    "        models: list of (name, model, tokenizer)\n",
    "        test_data: pd.DataFrame with 'text' and 'label'\n",
    "        weights: dict with weights for metrics\n",
    "        batch_size: evaluation batch size\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with metrics and final weighted score\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'accuracy': 0.4, 'mcc': 0.2, 'nit': 0.2,'runtime': 0.1, 'params': 0.05, 'nonzero_params': 0.05}\n",
    "\n",
    "    all_metrics = {}\n",
    "\n",
    "    # Step 1: compute metrics for all models\n",
    "    for name, model, tokenizer in model_list:\n",
    "      print(f\"Evaluating {name}...\")\n",
    "      try:\n",
    "          metrics = evaluate_model_metrics(model, tokenizer, test_data, batch_size=batch_size)\n",
    "          all_metrics[name] = metrics\n",
    "      except Exception as e:\n",
    "          print(f\"Error evaluating {name}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_metrics).T\n",
    "\n",
    "    # Step 2: min-max scale each metric (higher is better for final score)\n",
    "    df_scaled = df.copy()\n",
    "\n",
    "    # For metrics where lower is better (runtime, total_params, nonzero_params)\n",
    "    for col in ['runtime_sec', 'total_params', 'nonzero_params']:\n",
    "        col_normalization = col + \"_norm\"\n",
    "        df_scaled[col_normalization] = 1 / ((df[col] - df[col].min()) / (df[col].max() - df[col].min() + 1e-8) + 0.5)\n",
    "\n",
    "    # Step 3: compute final weighted score\n",
    "    df_scaled['final_score'] = (\n",
    "        weights['accuracy'] * df_scaled['accuracy'] +\n",
    "        weights['mcc'] * df_scaled['mcc'] +\n",
    "        weights['nit'] * df_scaled['nit'] +\n",
    "        weights['runtime'] * df_scaled['runtime_sec_norm'] +\n",
    "        weights['params'] * df_scaled['total_params_norm'] +\n",
    "        weights['nonzero_params'] * df_scaled['nonzero_params_norm']\n",
    "    )\n",
    "\n",
    "    # Sort by final score\n",
    "    df_scaled = df_scaled.sort_values(by='final_score', ascending=False)\n",
    "\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBJ-X-A8Se6L",
    "outputId": "c8bf467b-05e9-438b-8eab-b5d5984ec1b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc5...\n",
      "Evaluating distilbert_exc4...\n",
      "Evaluating distilbert_exc5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_exc4_pruned...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_pruned...\n",
      "Evaluating distilbert_exc4_pruned...\n",
      "Evaluating distilbert_pruned...\n",
      "Evaluating distilroberta_exc4-base...\n",
      "Evaluating distilroberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinybert_exc4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinybert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4_quantized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_quantized...\n",
      "Evaluating distilbert_exc4_quantized...\n",
      "Evaluating distilbert_quantized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4_LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc5_LoRA...\n",
      "Evaluating distilbert_exc4_LoRA...\n",
      "Evaluating distilbert_exc5_LoRA...\n",
      "Index(['accuracy', 'f1', 'mcc', 'nit', 'conf_matrix', 'runtime_sec',\n",
      "       'total_params', 'nonzero_params', 'runtime_sec_norm',\n",
      "       'total_params_norm', 'nonzero_params_norm', 'final_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# start evaluation\n",
    "evaluation_df = evaluate_and_score_models(model_list, test_data)\n",
    "print(evaluation_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "PalZZYqiSgzK",
    "outputId": "4e7e9450-af0c-49e2-9e75-2d6605c502f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>nit</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_params</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilbert_quantized</th>\n",
       "      <td>0.749342</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.681289</td>\n",
       "      <td>0.498732</td>\n",
       "      <td>81.179543</td>\n",
       "      <td>23854080</td>\n",
       "      <td>0.834644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_pruned</th>\n",
       "      <td>0.747499</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.493489</td>\n",
       "      <td>111.000188</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.755882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_quantized</th>\n",
       "      <td>0.736177</td>\n",
       "      <td>0.74678</td>\n",
       "      <td>0.665713</td>\n",
       "      <td>0.479057</td>\n",
       "      <td>147.900836</td>\n",
       "      <td>39037440</td>\n",
       "      <td>0.755628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc5</th>\n",
       "      <td>0.750132</td>\n",
       "      <td>0.76129</td>\n",
       "      <td>0.682747</td>\n",
       "      <td>0.500303</td>\n",
       "      <td>112.623321</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.74863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_quantized</th>\n",
       "      <td>0.604529</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.497042</td>\n",
       "      <td>0.322598</td>\n",
       "      <td>73.134276</td>\n",
       "      <td>23854080</td>\n",
       "      <td>0.710575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc5</th>\n",
       "      <td>0.748289</td>\n",
       "      <td>0.75888</td>\n",
       "      <td>0.681719</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>207.331913</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.67807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinybert</th>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.386043</td>\n",
       "      <td>0.316721</td>\n",
       "      <td>0.206525</td>\n",
       "      <td>15.833664</td>\n",
       "      <td>14351813</td>\n",
       "      <td>0.667367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinybert_exc4</th>\n",
       "      <td>0.373354</td>\n",
       "      <td>0.331221</td>\n",
       "      <td>0.288318</td>\n",
       "      <td>0.194163</td>\n",
       "      <td>16.137797</td>\n",
       "      <td>14351813</td>\n",
       "      <td>0.645317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_pruned</th>\n",
       "      <td>0.61901</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>0.518997</td>\n",
       "      <td>0.350883</td>\n",
       "      <td>122.14757</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.638605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4</th>\n",
       "      <td>0.630332</td>\n",
       "      <td>0.642991</td>\n",
       "      <td>0.533828</td>\n",
       "      <td>0.346945</td>\n",
       "      <td>116.28835</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.638409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4_quantized</th>\n",
       "      <td>0.522643</td>\n",
       "      <td>0.54012</td>\n",
       "      <td>0.394144</td>\n",
       "      <td>0.248381</td>\n",
       "      <td>148.611607</td>\n",
       "      <td>39037440</td>\n",
       "      <td>0.569498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilroberta-base</th>\n",
       "      <td>0.537915</td>\n",
       "      <td>0.544353</td>\n",
       "      <td>0.439142</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>113.883088</td>\n",
       "      <td>82122245</td>\n",
       "      <td>0.55594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilroberta_exc4-base</th>\n",
       "      <td>0.532122</td>\n",
       "      <td>0.53957</td>\n",
       "      <td>0.429216</td>\n",
       "      <td>0.263544</td>\n",
       "      <td>104.209126</td>\n",
       "      <td>82122245</td>\n",
       "      <td>0.555223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4</th>\n",
       "      <td>0.592417</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.48801</td>\n",
       "      <td>0.306697</td>\n",
       "      <td>170.933801</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.548685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_pruned</th>\n",
       "      <td>0.548183</td>\n",
       "      <td>0.464587</td>\n",
       "      <td>0.431959</td>\n",
       "      <td>0.38172</td>\n",
       "      <td>205.320812</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.533853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4_LoRA</th>\n",
       "      <td>0.375197</td>\n",
       "      <td>0.330316</td>\n",
       "      <td>0.201075</td>\n",
       "      <td>0.132575</td>\n",
       "      <td>246.674712</td>\n",
       "      <td>125538826</td>\n",
       "      <td>0.350525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_exc4_pruned</th>\n",
       "      <td>0.339389</td>\n",
       "      <td>0.273564</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.098568</td>\n",
       "      <td>221.461156</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.341259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_LoRA</th>\n",
       "      <td>0.28752</td>\n",
       "      <td>0.116906</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>130.14696</td>\n",
       "      <td>67699210</td>\n",
       "      <td>0.333542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc5_LoRA</th>\n",
       "      <td>0.280147</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.01953</td>\n",
       "      <td>135.851655</td>\n",
       "      <td>67699210</td>\n",
       "      <td>0.32213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc5_LoRA</th>\n",
       "      <td>0.308057</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0.094354</td>\n",
       "      <td>0.085948</td>\n",
       "      <td>248.667155</td>\n",
       "      <td>125538826</td>\n",
       "      <td>0.292617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  accuracy        f1       mcc       nit  \\\n",
       "distilbert_quantized              0.749342  0.759337  0.681289  0.498732   \n",
       "distilbert_pruned                 0.747499  0.757465  0.678261  0.493489   \n",
       "roberta_sentiment_quantized       0.736177   0.74678  0.665713  0.479057   \n",
       "distilbert_exc5                   0.750132   0.76129  0.682747  0.500303   \n",
       "distilbert_exc4_quantized         0.604529  0.616722  0.497042  0.322598   \n",
       "roberta_sentiment_exc5            0.748289   0.75888  0.681719  0.498854   \n",
       "tinybert                          0.406793  0.386043  0.316721  0.206525   \n",
       "tinybert_exc4                     0.373354  0.331221  0.288318  0.194163   \n",
       "distilbert_exc4_pruned             0.61901  0.633854  0.518997  0.350883   \n",
       "distilbert_exc4                   0.630332  0.642991  0.533828  0.346945   \n",
       "roberta_sentiment_exc4_quantized  0.522643   0.54012  0.394144  0.248381   \n",
       "distilroberta-base                0.537915  0.544353  0.439142  0.271259   \n",
       "distilroberta_exc4-base           0.532122   0.53957  0.429216  0.263544   \n",
       "roberta_sentiment_exc4            0.592417    0.6065   0.48801  0.306697   \n",
       "roberta_pruned                    0.548183  0.464587  0.431959   0.38172   \n",
       "roberta_sentiment_exc4_LoRA       0.375197  0.330316  0.201075  0.132575   \n",
       "roberta_exc4_pruned               0.339389  0.273564    0.1888  0.098568   \n",
       "distilbert_exc4_LoRA               0.28752  0.116906  0.044334  0.033471   \n",
       "distilbert_exc5_LoRA              0.280147  0.110438  0.028135   0.01953   \n",
       "roberta_sentiment_exc5_LoRA       0.308057  0.194544  0.094354  0.085948   \n",
       "\n",
       "                                 runtime_sec total_params final_score  \n",
       "distilbert_quantized               81.179543     23854080    0.834644  \n",
       "distilbert_pruned                 111.000188     66957317    0.755882  \n",
       "roberta_sentiment_quantized       147.900836     39037440    0.755628  \n",
       "distilbert_exc5                   112.623321     66957317     0.74863  \n",
       "distilbert_exc4_quantized          73.134276     23854080    0.710575  \n",
       "roberta_sentiment_exc5            207.331913    124649477     0.67807  \n",
       "tinybert                           15.833664     14351813    0.667367  \n",
       "tinybert_exc4                      16.137797     14351813    0.645317  \n",
       "distilbert_exc4_pruned             122.14757     66957317    0.638605  \n",
       "distilbert_exc4                    116.28835     66957317    0.638409  \n",
       "roberta_sentiment_exc4_quantized  148.611607     39037440    0.569498  \n",
       "distilroberta-base                113.883088     82122245     0.55594  \n",
       "distilroberta_exc4-base           104.209126     82122245    0.555223  \n",
       "roberta_sentiment_exc4            170.933801    124649477    0.548685  \n",
       "roberta_pruned                    205.320812    124649477    0.533853  \n",
       "roberta_sentiment_exc4_LoRA       246.674712    125538826    0.350525  \n",
       "roberta_exc4_pruned               221.461156    124649477    0.341259  \n",
       "distilbert_exc4_LoRA               130.14696     67699210    0.333542  \n",
       "distilbert_exc5_LoRA              135.851655     67699210     0.32213  \n",
       "roberta_sentiment_exc5_LoRA       248.667155    125538826    0.292617  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df[['accuracy', 'f1', 'mcc', 'nit', 'runtime_sec', 'total_params', 'final_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2YLn2-884Dr"
   },
   "source": [
    "<center><h1>END</h1></center>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Deep)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "011b082537ca40cc9f001a9ecb417150": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ce6d0b573045cf94c697d73664b793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "132b638de7b54d63ab7f59b8ef7f97a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d30d7bc1e244ee89d990f696278c46d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e21347367064dd2b4b8e32cd3ac948e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ff6182374c5403297f5cd0e67a98b0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48a1b44306ac4339bf547db45452905f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "4a58443311f84dcb8873ceaa82386220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c8569c2302641a3896e04eca26d2716",
       "IPY_MODEL_635b08f4d23b4107984758b9d9abd0bf",
       "IPY_MODEL_856b19f367a542c0a939af0a85222689"
      ],
      "layout": "IPY_MODEL_8a1b7313da7b4966a630c5a0332ffe5d"
     }
    },
    "605d7c42c6d54d21906c0a8fa15a1058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "635b08f4d23b4107984758b9d9abd0bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_011b082537ca40cc9f001a9ecb417150",
      "max": 629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_605d7c42c6d54d21906c0a8fa15a1058",
      "value": 629
     }
    },
    "673cad9e688f4060974464df72e3663e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7840f2c5cad34566a6f01f025d1a93c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f11f1b779456f950c7e77bcbcb796",
      "placeholder": "​",
      "style": "IPY_MODEL_c6e9babebe5d49b7b9504a424fc3940e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "7c8569c2302641a3896e04eca26d2716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecb41a290efb4ed7890f289e8d9b1d9e",
      "placeholder": "​",
      "style": "IPY_MODEL_fe4213350390437eb8cc0a7442f6cfac",
      "value": "config.json: 100%"
     }
    },
    "8191b5069db34fb98a5012f4bec90aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48a1b44306ac4339bf547db45452905f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e800f6ddb4a444ab9dacb6ef976d8fae",
      "value": 1
     }
    },
    "856b19f367a542c0a939af0a85222689": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ff6182374c5403297f5cd0e67a98b0b",
      "placeholder": "​",
      "style": "IPY_MODEL_f01ee8c5ca13453fb54486df8a03bae2",
      "value": " 629/629 [00:00&lt;00:00, 77.5kB/s]"
     }
    },
    "85facf5f48244ddebf2475e1f7b3530a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7840f2c5cad34566a6f01f025d1a93c2",
       "IPY_MODEL_fd1801af21ef4baf93ee40aa1603b7bf",
       "IPY_MODEL_9dcabb9cf97142a8874c929fd6fc0dee"
      ],
      "layout": "IPY_MODEL_c6b1f646d12d42a493cc34ccf1e6d5bf"
     }
    },
    "8a1b7313da7b4966a630c5a0332ffe5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92416a94833a4fc48b95a0794cac4227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9630ecb76a0d46b9aed453c6332cea8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec1fc9fa806344d58b27071b665bfd39",
      "placeholder": "​",
      "style": "IPY_MODEL_980df6a941334ca28d44fe03d0a95331",
      "value": "model.safetensors: 100%"
     }
    },
    "980df6a941334ca28d44fe03d0a95331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "982f11f1b779456f950c7e77bcbcb796": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dcabb9cf97142a8874c929fd6fc0dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_673cad9e688f4060974464df72e3663e",
      "placeholder": "​",
      "style": "IPY_MODEL_3e21347367064dd2b4b8e32cd3ac948e",
      "value": " 48.0/48.0 [00:00&lt;00:00, 4.33kB/s]"
     }
    },
    "a0db8cf5880548f694c3bb87cd52c910": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a14e41092fab4cfe9a3f3cfa6dc34e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c04be2c2385f437cafd026f227cc516f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c16b192206814e52a9ab3d7a506bafa1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6b1f646d12d42a493cc34ccf1e6d5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e9babebe5d49b7b9504a424fc3940e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cec858cb70cf439c88eaee9d545b418b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a14e41092fab4cfe9a3f3cfa6dc34e02",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f24bd2cf2c4b0d92a4bc917e1a4e38",
      "value": " 268M/268M [00:01&lt;00:00, 153MB/s]"
     }
    },
    "d3b466db3a4d4260822d31465949a3f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc5af28496cc452b9a25d542ee4a9b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9630ecb76a0d46b9aed453c6332cea8f",
       "IPY_MODEL_f93463a1f0be4810868e6f541f257ad9",
       "IPY_MODEL_cec858cb70cf439c88eaee9d545b418b"
      ],
      "layout": "IPY_MODEL_c16b192206814e52a9ab3d7a506bafa1"
     }
    },
    "e7d816c566c84c03a80f8f2c686d69e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fff6f223d42e445b9c4a956091a957ee",
       "IPY_MODEL_8191b5069db34fb98a5012f4bec90aeb",
       "IPY_MODEL_ebc9af464ef44b418c7c37b29f214ff1"
      ],
      "layout": "IPY_MODEL_d3b466db3a4d4260822d31465949a3f8"
     }
    },
    "e800f6ddb4a444ab9dacb6ef976d8fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e89b8b5f4e6340f7a0f5d5257e23778e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebc9af464ef44b418c7c37b29f214ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d30d7bc1e244ee89d990f696278c46d",
      "placeholder": "​",
      "style": "IPY_MODEL_132b638de7b54d63ab7f59b8ef7f97a1",
      "value": " 232k/? [00:00&lt;00:00, 18.1MB/s]"
     }
    },
    "ec1fc9fa806344d58b27071b665bfd39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb41a290efb4ed7890f289e8d9b1d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01ee8c5ca13453fb54486df8a03bae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7f24bd2cf2c4b0d92a4bc917e1a4e38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f93463a1f0be4810868e6f541f257ad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0db8cf5880548f694c3bb87cd52c910",
      "max": 267832558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10ce6d0b573045cf94c697d73664b793",
      "value": 267832558
     }
    },
    "fd1801af21ef4baf93ee40aa1603b7bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c04be2c2385f437cafd026f227cc516f",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92416a94833a4fc48b95a0794cac4227",
      "value": 48
     }
    },
    "fe1655958eca43fabc99ee72c4d0a581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe4213350390437eb8cc0a7442f6cfac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fff6f223d42e445b9c4a956091a957ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe1655958eca43fabc99ee72c4d0a581",
      "placeholder": "​",
      "style": "IPY_MODEL_e89b8b5f4e6340f7a0f5d5257e23778e",
      "value": "vocab.txt: "
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
