{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMxcJr83oekRP/BQCnWPBaX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cf92ad75151648d487f0d031a659ccb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83900a71a8de4c6bbf956912b4159dc9","IPY_MODEL_445dff50291c4b789ada1c83999fdaaa","IPY_MODEL_9dec9d8ecb454da28d937ea23bc0df94"],"layout":"IPY_MODEL_3b812a018264475b87ddf2d6a329dcd4"}},"83900a71a8de4c6bbf956912b4159dc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60deb318787f44eeafda242808d1d596","placeholder":"​","style":"IPY_MODEL_1297671bdf3848ed9372c9d770236d13","value":"tokenizer_config.json: 100%"}},"445dff50291c4b789ada1c83999fdaaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_601a7e93f2df445d91550fb91d483392","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65cc0118e6774b449cfe2ba2a06c919f","value":48}},"9dec9d8ecb454da28d937ea23bc0df94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_084660b783c849b0915f8965186c33ca","placeholder":"​","style":"IPY_MODEL_63d0f605c96a4652b650a44d4e625b23","value":" 48.0/48.0 [00:00&lt;00:00, 4.50kB/s]"}},"3b812a018264475b87ddf2d6a329dcd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60deb318787f44eeafda242808d1d596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1297671bdf3848ed9372c9d770236d13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"601a7e93f2df445d91550fb91d483392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65cc0118e6774b449cfe2ba2a06c919f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"084660b783c849b0915f8965186c33ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d0f605c96a4652b650a44d4e625b23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"629687e86994481ba938fc37690339e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcdb6ea81e5645de958dc893fd164755","IPY_MODEL_957b3c548dfc46ea89edbe53cb205e29","IPY_MODEL_7e89ef7c1efa47a79a77526f226e214c"],"layout":"IPY_MODEL_e39dda2a478a4d968196a6f2f4f0f895"}},"dcdb6ea81e5645de958dc893fd164755":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d84b46e1f2da4e69962b1e19b0d21dcf","placeholder":"​","style":"IPY_MODEL_44b6fd0feba246c6a7538131771cfde3","value":"config.json: 100%"}},"957b3c548dfc46ea89edbe53cb205e29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e72c4c7b57ef48a48657f9a1914f9ec8","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0c603fc75894f87aacd4cfabb5e9dee","value":629}},"7e89ef7c1efa47a79a77526f226e214c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12af19ba02c5453badee49490795e52f","placeholder":"​","style":"IPY_MODEL_4978da207d134e19a1a06fb628201ddf","value":" 629/629 [00:00&lt;00:00, 50.7kB/s]"}},"e39dda2a478a4d968196a6f2f4f0f895":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84b46e1f2da4e69962b1e19b0d21dcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b6fd0feba246c6a7538131771cfde3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e72c4c7b57ef48a48657f9a1914f9ec8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0c603fc75894f87aacd4cfabb5e9dee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12af19ba02c5453badee49490795e52f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4978da207d134e19a1a06fb628201ddf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"385051742bbf43f6ba4e7413b0247b7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78b5b82f78634c38aa053becdb626474","IPY_MODEL_78002c44c6fc4b50ac8fa0bae2b4241b","IPY_MODEL_47a79e3b7ba54531bd2d4ef25456bb33"],"layout":"IPY_MODEL_d82a2a7743a748df9f2903ae98295deb"}},"78b5b82f78634c38aa053becdb626474":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21f6eb2ed5b9419d915e1dd011016df3","placeholder":"​","style":"IPY_MODEL_2cc93a5c9aa3424493e7f583e3efcdb4","value":"vocab.txt: "}},"78002c44c6fc4b50ac8fa0bae2b4241b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f690fee1a4846efb265c52232e15485","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b0ac8357dc04949816fbd744ac21645","value":1}},"47a79e3b7ba54531bd2d4ef25456bb33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16f166ea4485494291a1d8a949e4868d","placeholder":"​","style":"IPY_MODEL_04fa2efb5ab2419cb240270f94a755bc","value":" 232k/? [00:00&lt;00:00, 14.1MB/s]"}},"d82a2a7743a748df9f2903ae98295deb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f6eb2ed5b9419d915e1dd011016df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc93a5c9aa3424493e7f583e3efcdb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f690fee1a4846efb265c52232e15485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7b0ac8357dc04949816fbd744ac21645":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16f166ea4485494291a1d8a949e4868d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04fa2efb5ab2419cb240270f94a755bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d482ec29abc4866893269fa221ca158":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82deed60de1c4f28a29daeed0d4f4c15","IPY_MODEL_6953fa3a1f0c4ece9bbf725c679c62f2","IPY_MODEL_27999885d0644b7190ed17ec11fad140"],"layout":"IPY_MODEL_4050421e932646f1840ca28d14f0c0d1"}},"82deed60de1c4f28a29daeed0d4f4c15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_560ac97701ca4db4bc4f8db36b17d2af","placeholder":"​","style":"IPY_MODEL_f888a4e0947e45ab989a0455e07b5f66","value":"model.safetensors: 100%"}},"6953fa3a1f0c4ece9bbf725c679c62f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad07c6ceba4546cb8564252d0fe38330","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38783cd321824e8c920d40c7ebcbcd40","value":267832558}},"27999885d0644b7190ed17ec11fad140":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfeb33a06c7842ecae13bc814e33f068","placeholder":"​","style":"IPY_MODEL_66ca3304fb5c4c24b590bd0552fedf3d","value":" 268M/268M [00:03&lt;00:00, 87.9MB/s]"}},"4050421e932646f1840ca28d14f0c0d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"560ac97701ca4db4bc4f8db36b17d2af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f888a4e0947e45ab989a0455e07b5f66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad07c6ceba4546cb8564252d0fe38330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38783cd321824e8c920d40c7ebcbcd40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfeb33a06c7842ecae13bc814e33f068":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ca3304fb5c4c24b590bd0552fedf3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["\n","<center><br><font size=6>Final Project</font><br>\n","<font size=5>Advanced Topics in Deep Learning</font><br>\n","<b><font size=4>Part B</font></b>\n","<br><font size=4>Training Models like Excercise 4</font><br><br>\n","Authors: Ido Rappaport & Eran Tascesme\n","</font></center>\n","\n","**Submission Details:**\n","<font size=2>\n","<br>Ido Rappaport, ID: 322891623\n","<br>Eran Tascesme , ID: 205708720 </font>\n"],"metadata":{"id":"eoyALLr0bNOE"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1pQkvA0y6Y2","executionInfo":{"status":"ok","timestamp":1755441980613,"user_tz":-180,"elapsed":34002,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}},"outputId":"dce9447b-ca41-42f8-b74c-f2809019e0b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.43)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.34.1)\n","Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Requirement already satisfied: nlpaug in /usr/local/lib/python3.11/dist-packages (1.1.11)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (1.26.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.2.2)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.32.3)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (3.18.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2025.8.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (4.14.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"]}],"source":["'''\n","!pip install optuna\n","!pip install wandb\n","!pip install nlpaug\n","!pip install gensim\n","!pip install evaluate\n","'''"]},{"cell_type":"markdown","source":["**Import libraries**"],"metadata":{"id":"A1L3bp_8b151"}},{"cell_type":"code","source":["# Standard libraries\n","import os\n","import re\n","import string\n","import random\n","import warnings\n","from collections import Counter\n","\n","# Data handling and visualization\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from pathlib import Path\n","\n","# NLP libraries\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","from gensim import corpora, models\n","from urllib.parse import urlparse\n","\n","# Machine learning and deep learning\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from torch import nn, optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import (\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    accuracy_score,\n","    classification_report,\n","    confusion_matrix,\n","    ConfusionMatrixDisplay\n",")\n","\n","# Hugging Face Transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    EarlyStoppingCallback,\n","    set_seed,\n","    TrainerCallback,\n","    TrainerState,\n","    TrainerControl,\n","    DataCollatorWithPadding,\n","    RobertaForSequenceClassification,\n","    MarianMTModel,\n","    MarianTokenizer\n",")\n","from datasets import Dataset, DatasetDict, load_dataset\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","import evaluate\n","\n","# Other libraries\n","import optuna\n","import wandb\n","from tqdm import tqdm\n","\n","# Filter warnings\n","warnings.filterwarnings('ignore')\n","\n","# Download NLTK resources\n","try:\n","    nltk.data.find('tokenizers/punkt')\n","except LookupError:\n","    nltk.download('punkt')\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')"],"metadata":{"id":"aB1LkOmnzJ9F","executionInfo":{"status":"ok","timestamp":1755442015276,"user_tz":-180,"elapsed":25013,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mjYdbBgzftQ","executionInfo":{"status":"ok","timestamp":1755442072373,"user_tz":-180,"elapsed":48870,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}},"outputId":"298401a9-42de-44ab-d08a-566d1504cf25"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from huggingface_hub import login\n","login('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')"],"metadata":{"id":"TBDjyqHXzhsG","executionInfo":{"status":"ok","timestamp":1755442124649,"user_tz":-180,"elapsed":284,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BoK9Q14Xzij5","executionInfo":{"status":"ok","timestamp":1755442127156,"user_tz":-180,"elapsed":10,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}},"outputId":"991e1901-bda4-43a2-8db9-725e369e64cd"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**Load 4 CSV Files**\n","1. dirty - the original set from kaggle\n","2. clean - after removing signs and stopwords\n","3. cutted - after removing short/long tweets\n","4. balanced - after augmentation"],"metadata":{"id":"lBaTf2CrcCqk"}},{"cell_type":"code","source":["# Load CSV files\n","\n","drive_path = \"/content/drive/My Drive/Colab Notebooks/\"\n","\n","train_dirty = pd.read_csv(drive_path + \"train_dirty.csv\", encoding=\"ISO-8859-1\")\n","train_clean = pd.read_csv(drive_path + \"train_clean.csv\", encoding=\"ISO-8859-1\")\n","train_cutted = pd.read_csv(drive_path + \"train_cutted.csv\", encoding=\"ISO-8859-1\")\n","train_balanced = pd.read_csv(drive_path + \"train_balanced.csv\", encoding=\"ISO-8859-1\")\n","\n","val_dirty = pd.read_csv(drive_path + \"val_dirty.csv\", encoding=\"ISO-8859-1\")\n","val_clean = pd.read_csv(drive_path + \"val_clean.csv\", encoding=\"ISO-8859-1\")\n","val_cutted = pd.read_csv(drive_path + \"val_cutted.csv\", encoding=\"ISO-8859-1\")\n","val_balanced = val_cutted.copy()  # augmentation is just on the train set."],"metadata":{"id":"0dYwQ6h5zmyn","executionInfo":{"status":"ok","timestamp":1755442243845,"user_tz":-180,"elapsed":401,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**Tweet Dataset Class**\n","\n","This class is a custom PyTorch Dataset to handle the tweet data. It tokenizes the text and prepares it for use with a transformer model. It includes filtering for empty texts."],"metadata":{"id":"FUgVjKh_cghK"}},{"cell_type":"code","source":["class TweetDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer):\n","        # Ensure 'text' column is string type and filter out any empty strings\n","        self.dataframe = dataframe.copy()\n","        self.dataframe['text'] = self.dataframe['text'].astype(str)\n","        self.dataframe = self.dataframe[self.dataframe['text'].str.strip().astype(bool)].reset_index(drop=True)\n","\n","        self.texts = self.dataframe['text'].tolist()\n","        self.labels = self.dataframe['label'].tolist()\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","\n","        # Add a check for empty text after retrieval (should be rare after filtering in __init__)\n","        if not text or not text.strip():\n","             print(f\"Warning: Empty text found at index {idx}. This should ideally be filtered in __init__.\")\n","             # Handle this case, e.g., return a dummy or skip.\n","             # For now, let's assume filtered data is clean.\n","             # If not, collate_fn needs to handle None.\n","\n","             # Returning None requires changes in the DataLoader's collate_fn.\n","             # Given filtering in __init__, this check is mostly for robustness.\n","             # If data is truly problematic at this stage, consider raising an error or more robust filtering.\n","             # For robustness, ensure text is string here too, though __init__ should handle it.\n","             if not isinstance(text, str):\n","                 print(f\"Warning: Non-string text found at index {idx}: {text} (type: {type(text)}).\")\n","                 # Option: Convert to string or handle as error\n","                 text = str(text) if text is not None else \"\" # Attempt conversion\n","\n","             if not text.strip():\n","                 return None # Return None if text is still empty after potential conversion\n","\n","        encoding = self.tokenizer(\n","            text,\n","            padding='max_length',\n","            truncation=True,\n","            max_length=512,\n","            return_tensors='pt'\n","        )\n","\n","        # Ensure the tensors are not empty after encoding\n","        if encoding['input_ids'].nelement() == 0:\n","             print(f\"Warning: Empty encoding for text at index {idx}: '{text}'.\")\n","             return None # Return None if encoding is empty\n","\n","        # Squeeze to remove batch dim (1) so shape is [seq_len]\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(0),\n","            'attention_mask': encoding['attention_mask'].squeeze(0),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }"],"metadata":{"id":"xBYjvXI-0YlF","executionInfo":{"status":"ok","timestamp":1755442249996,"user_tz":-180,"elapsed":1,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**Training Classes and Methods**\n","\n","We chose to train based on accuracy, but we also monitored other metrics such as loss, precision, recall, and F1-score.\n","\n","We used Adam as our optimizer and CrossEntropyLoss as our criterion.\n","\n","Additionally, we observed that freezing layers is done differently for various model types. To maintain generality, we added a model_type variable that allows us to freeze the layers accordingly.\n","\n","We opted for a small number of trials and epochs to save time and resources."],"metadata":{"id":"hs6dRvOWeg8b"}},{"cell_type":"code","source":["def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n","    early_stop_flag = False\n","    if current_val_accuracy > best_val_accuracy:\n","        best_val_accuracy = current_val_accuracy\n","        best_val_accuracy_epoch = current_val_accuracy_epoch\n","    else:\n","        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n","            early_stop_flag = True\n","    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag"],"metadata":{"id":"XPRm4dNx0buE","executionInfo":{"status":"ok","timestamp":1755442253662,"user_tz":-180,"elapsed":12,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train_model_with_hyperparams(model, project_name, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n","    best_val_accuracy = 0.0\n","    best_val_accuracy_epoch = 0\n","    early_stop_flag = False\n","    best_model_state = None\n","    print(f\"trail= {trial.number}\")\n","\n","    for epoch in range(1, epochs + 1):\n","        print(f\"epoch= {epoch}\")\n","        model.train()\n","        train_loss = 0.0\n","        total_train_samples = 0\n","        correct_train_predictions = 0\n","\n","        for batch in train_loader:  #Iterates over the train_loader, which is a DataLoader object containing batches of training data.\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            optimizer.zero_grad()   # Reset gradients\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) # Forward pass\n","            logits = outputs.logits   # save the logits (the raw output of the model)\n","            loss = criterion(logits, labels)   # Calculate loss\n","\n","            loss.backward() # Backward pass\n","            optimizer.step() # Update weights using the optimizer\n","\n","            # Accumulate training loss and predictions\n","            train_loss += loss.item() * input_ids.size(0)\n","            total_train_samples += input_ids.size(0)\n","            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n","\n","        train_loss /= total_train_samples\n","        train_accuracy = correct_train_predictions / total_train_samples\n","\n","        ###  Validation loop  ###\n","        model.eval() # Enable evaluation mode\n","        val_loss = 0.0\n","        total_val_samples = 0\n","        correct_val_predictions = 0\n","\n","        all_val_labels = []\n","        all_val_preds = []\n","\n","        with torch.no_grad(): # Disable gradient computation\n","            for batch in val_loader: # iterate on the val_loader's batches\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","\n","                outputs = model(input_ids, attention_mask=attention_mask)\n","                logits = outputs.logits\n","                loss = criterion(logits, labels)\n","\n","                val_loss += loss.item() * input_ids.size(0)\n","                total_val_samples += input_ids.size(0)\n","                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n","\n","                all_val_labels.extend(labels.cpu().numpy())\n","                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","\n","        # calculate metrics\n","        val_loss /= total_val_samples\n","        val_accuracy = correct_val_predictions / total_val_samples\n","        val_precision = precision_score(all_val_labels, all_val_preds, average='micro')\n","        val_recall = recall_score(all_val_labels, all_val_preds, average='micro')\n","        val_f1 = f1_score(all_val_labels, all_val_preds, average='micro')\n","\n","        # Check for early stopping\n","        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch)\n","\n","        # Save the best model under the best_model_state parameter\n","        if val_accuracy == best_val_accuracy:\n","            best_model_state = model.state_dict()\n","\n","        # Log metrics to Weights & Biases - THIS IS WHERE WE TRACK THE RESULTS AND THE PROCESS\n","        wandb.log({\n","            \"Epoch\": epoch,\n","            \"Train Loss\": train_loss,\n","            \"Train Accuracy\": train_accuracy,\n","            \"Validation Loss\": val_loss,\n","            \"Validation Accuracy\": val_accuracy,\n","            \"Validation Precision\": val_precision,\n","            \"Validation Recall\": val_recall,\n","            \"Validation F1\": val_f1})\n","\n","        if early_stop_flag:  # Checks whether the early stopping condition has been met, as indicated by the early_stop_flag\n","            break# Exits the training loop immediately if the early stopping condition is satisfied\n","\n","    if best_model_state is not None: # Save the best model as a .pt file\n","        base_output_dir = \"/content/drive/My Drive/Colab Notebooks/models\"\n","        output_dir = os.path.join(base_output_dir, project_name)\n","        os.makedirs(output_dir, exist_ok=True)\n","        sanitized_model_name = model_name.replace(\"/\", \"-\")\n","        file_path = os.path.join(output_dir, f\"best_{sanitized_model_name}_model_trial_{trial.number}.pt\")\n","\n","        torch.save(best_model_state, file_path)\n","\n","    return best_val_accuracy"],"metadata":{"id":"FVOGHIIY0eLT","executionInfo":{"status":"ok","timestamp":1755442254886,"user_tz":-180,"elapsed":4,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Objective Function for Optuna\n","def objective(trial, train_df, eval_df, project_name, model_name, autotokenizer, automodelclassification, model_type):\n","    # Hyperparameter suggestions\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n","    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-4)\n","    patience = trial.suggest_int(\"patience\", 3, 4)\n","    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128])\n","    num_layers = trial.suggest_int(\"num_layers\", 1, 2)\n","\n","    train_dataset = TweetDataset(train_df, autotokenizer)\n","    val_dataset = TweetDataset(eval_df, autotokenizer)\n","\n","    def collate_fn(batch):\n","        # Filter out None values from the batch\n","        batch = [item for item in batch if item is not None]\n","        if not batch: # Return None if the batch is empty after filtering\n","            return None\n","        input_ids = torch.stack([item['input_ids'] for item in batch])\n","        attention_mask = torch.stack([item['attention_mask'] for item in batch])\n","        labels = torch.stack([item['labels'] for item in batch])\n","        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn) # insert into a DataLoader\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn) # insert into a DataLoader\n","\n","    model = automodelclassification.to(device)\n","\n","    if model_type == \"roberta\":\n","        # Freeze all RoBERTa layers\n","        for param in model.roberta.parameters():\n","            param.requires_grad = False\n","\n","        # Unfreeze last `num_layers` encoder layers\n","        for param in model.roberta.encoder.layer[-num_layers:].parameters():\n","            param.requires_grad = True\n","\n","        # Unfreeze the classifier head\n","        for param in model.classifier.parameters():\n","            param.requires_grad = True\n","\n","    elif model_type == \"dilbert\":\n","        # Freeze all distilber layers\n","        backbone = model.distilbert\n","        for p in backbone.parameters():\n","            p.requires_grad = False\n","        # # Unfreeze last `num_layers` encoder layers\n","        for p in backbone.transformer.layer[-num_layers:].parameters():\n","            p.requires_grad = True\n","\n","        # # Unfreeze the classifier head\n","        if hasattr(model, \"pre_classifier\"):\n","            for p in model.pre_classifier.parameters():\n","                p.requires_grad = True\n","        for p in model.classifier.parameters():\n","            p.requires_grad = True\n","\n","    # Define optimizer and loss function\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n","    wandb.init(project=project_name,\n","               config={\n","        \"learning_rate\": learning_rate,\n","        \"weight_decay\": weight_decay,\n","        \"patience\": patience,\n","        \"batch_size\": batch_size,\n","        \"num_layers\": num_layers,\n","        \"architecture\": model_name,\n","        \"dataset\": \"Corona_NLP\"},\n","        name=f\"trial_{trial.number}\") # The name that will be saved in the W&B platform\n","\n","    # Train the model and get the best validation accuracy\n","    best_val_accuracy = train_model_with_hyperparams(model, project_name, train_loader, val_loader, optimizer, criterion, epochs=6, patience=patience, trial=trial)\n","\n","    wandb.finish() # Finish the Weights & Biases run\n","\n","    return best_val_accuracy # Return best validation acc as the objective to maximize"],"metadata":{"id":"5cnZg-qp0oJb","executionInfo":{"status":"ok","timestamp":1755442258410,"user_tz":-180,"elapsed":16,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**First Model**\n","\n","twitter-roberta-base-sentiment\n","\n","We trained the model on 4 Datasets: dirty, clean, cutted and balanced\n"],"metadata":{"id":"KHl87LbKe6SD"}},{"cell_type":"code","source":["model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n","model_type = \"roberta\"\n","autotokenizer = AutoTokenizer.from_pretrained(model_name)\n","automodelclassification = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)"],"metadata":{"id":"V5FPWEBR1DO1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"roberta_sentiment_dirty_data_exc4\"\n","\n","roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n","roberta_sentiment_study.optimize(partial(objective, train_df=train_dirty, eval_df=val_dirty, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"lyTVYKGY0v6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"roberta_sentiment_clean_data_exc4\"\n","\n","roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n","roberta_sentiment_study.optimize(partial(objective, train_df=train_clean, eval_df=val_clean, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"kFg3q0Ph01up"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"roberta_sentiment_cutted_data_exc4\"\n","\n","roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n","roberta_sentiment_study.optimize(partial(objective, train_df=train_cutted, eval_df=val_cutted, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"CYdKDRXv07Lh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"roberta_sentiment_balanced_data_exc4\"\n","\n","roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n","roberta_sentiment_study.optimize(partial(objective, train_df=train_balanced, eval_df=val_balanced, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"QFRZ3Xna09DD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Second Model**\n","\n","distilbert-base-uncased-finetuned-sst-2-english\n","\n","We trained the model on 4 Datasets: dirty, clean, cutted and balanced\n"],"metadata":{"id":"P8b_AlBEfYby"}},{"cell_type":"code","source":["model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","model_type = \"dilbert\"\n","autotokenizer = AutoTokenizer.from_pretrained(model_name)\n","automodelclassification = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    num_labels=5,\n","    ignore_mismatched_sizes=True\n",")"],"metadata":{"id":"fORbP8j32nm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"distilbert_sentiment_dirty_data_exc4\"\n","\n","distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n","distilber_sentiment_study.optimize(partial(objective, train_df=train_dirty, eval_df=val_dirty, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"kpIcUyTa21s3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"distilbert_sentiment_clean_data_exc4\"\n","\n","distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n","distilber_sentiment_study.optimize(partial(objective, train_df=train_clean, eval_df=val_clean, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"EG45X6uM29tR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"distilbert_sentiment_cutted_data_exc4\"\n","\n","distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n","distilber_sentiment_study.optimize(partial(objective, train_df=train_cutted, eval_df=val_cutted, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"sU0QMlhk3Eob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_name = \"distilbert_sentiment_balanced_data_exc4\"\n","\n","distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n","distilber_sentiment_study.optimize(partial(objective, train_df=train_balanced, eval_df=val_balanced, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n","               n_trials=5)"],"metadata":{"id":"VUvtX3vD2_qV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Choosing the best model for each model type**\n","\n","By looking on W&B we found that the most stable training was on the augmented dataset. Therefore, we will continue with the model trained on this specific set, as it yielded the highest results on the test set."],"metadata":{"id":"POBRlsidPO69"}},{"cell_type":"code","source":["test_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/test_clean.csv\", encoding=\"ISO-8859-1\")\n","# Ensure the 'text' column is treated as string type\n","test_data['text'] = test_data['text'].astype(str)"],"metadata":{"id":"K18bteK4PPT9","executionInfo":{"status":"ok","timestamp":1755443600029,"user_tz":-180,"elapsed":24,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["This `find_and_save_best_model` function iterates through all saved model files (`.pt`) in a specified folder, evaluates each model's accuracy on the test dataset, and saves the model with the highest accuracy to a designated location with a given filename."],"metadata":{"id":"-atlv3MJSRTv"}},{"cell_type":"code","source":["# def find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name):\n","#     \"\"\"\n","#     Finds the best performing model based on accuracy on the test set\n","#     and saves it to a specified location.\n","\n","#     Args:\n","#         model_folder_path (str): The path to the folder containing the saved models (.pt files).\n","#         model_name (str): The name of the model architecture (e.g., \"cardiffnlp/twitter-roberta-base-sentiment-latest\").\n","#         model_save_path (str): The directory where the best model should be saved.\n","#         model_save_name (str): The filename for the best saved model.\n","#     \"\"\"\n","#     best_accuracy = 0.0\n","#     best_model_state_dict = None\n","#     best_model_filename = None\n","\n","#     # Assuming test_loader and criterion are accessible in this scope\n","#     # or passed as arguments if preferred.\n","#     # For now, assuming they are globally available from previous cells.\n","#     criterion = nn.CrossEntropyLoss() # Define criterion if not globally available\n","\n","#     # Ensure the save directory exists\n","#     os.makedirs(model_save_path, exist_ok=True)\n","\n","#     for filename in os.listdir(model_folder_path):\n","#         if filename.endswith(\".pt\"):\n","#             model_path = os.path.join(model_folder_path, filename)\n","#             print(f\"Loading and evaluating model: {filename}\")\n","\n","#             # Load the model state dictionary\n","#             model_state_dict = torch.load(model_path, map_location=device)\n","\n","#             # Initialize a new model with the same architecture\n","#             model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True).to(device)\n","\n","#             # Load the state dictionary into the model\n","#             model.load_state_dict(model_state_dict)\n","\n","#             # Evaluate the model\n","#             accuracy, loss, precision, recall, f1 = evaluate_model(model, test_loader, criterion)\n","\n","#             print(f\"  Accuracy: {accuracy:.4f}\")\n","\n","#             # Check if this model is the best so far\n","#             if accuracy > best_accuracy:\n","#                 best_accuracy = accuracy\n","#                 best_model_state_dict = model_state_dict\n","#                 best_model_filename = filename\n","\n","#     if best_model_state_dict is not None:\n","#         save_path = os.path.join(model_save_path, model_save_name)\n","#         torch.save(best_model_state_dict, save_path)\n","#         print(f\"\\nBest model found: {best_model_filename} with accuracy: {best_accuracy:.4f}\")\n","#         print(f\"Best model saved to: {save_path}\")\n","#     else:\n","#         print(\"No models found in the specified folder.\")"],"metadata":{"id":"CYtreBAbQtFP","executionInfo":{"status":"ok","timestamp":1755442275762,"user_tz":-180,"elapsed":3,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, dataloader, device):\n","    model.eval()\n","    preds, true_labels = [], []\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            predictions = torch.argmax(logits, dim=-1)\n","\n","            preds.extend(predictions.cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    return accuracy_score(true_labels, preds)\n","\n","def find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data, batch_size=16):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    test_dataset = TweetDataset(test_data, tokenizer)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    best_acc = -1.0\n","    best_state_dict = None\n","\n","    # Iterate over all .pt files\n","    for file_name in os.listdir(model_folder_path):\n","        if file_name.endswith(\".pt\"):\n","            print(f\"Evaluating {file_name}\")\n","            file_path = os.path.join(model_folder_path, file_name)\n","\n","            # Load model\n","            model = AutoModelForSequenceClassification.from_pretrained(\n","                model_name,\n","                num_labels=5, ignore_mismatched_sizes=True)\n","\n","            state_dict = torch.load(file_path, map_location=device)\n","\n","            # Handle both plain state_dict and dict with 'model_state_dict'\n","            if \"model_state_dict\" in state_dict:\n","                state_dict = state_dict[\"model_state_dict\"]\n","\n","            model.load_state_dict(state_dict)\n","            model.to(device)\n","\n","            acc = evaluate_model(model, test_loader, device)\n","            print(f\"Model {file_name} Accuracy: {acc:.4f}\")\n","\n","            if acc > best_acc:\n","                best_acc = acc\n","                best_state_dict = state_dict\n","\n","    if best_state_dict is not None:\n","        os.makedirs(model_save_path, exist_ok=True)\n","        save_path = os.path.join(model_save_path, model_save_name)\n","        torch.save(best_state_dict, save_path)\n","        print(f\"Best model saved at {save_path} with accuracy {best_acc:.4f}\")\n","    else:\n","        print(\" No .pt files found.\")\n"],"metadata":{"id":"TzODkVEdit-D","executionInfo":{"status":"ok","timestamp":1755443637118,"user_tz":-180,"elapsed":3,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["**First Model**\n","\n","find the best model of twitter-roberta-base-sentiment-latest"],"metadata":{"id":"4xnYkPQkT_5m"}},{"cell_type":"code","source":["model_folder_path = \"/content/drive/My Drive/Colab Notebooks/models/roberta_sentiment_balanced_data\"\n","model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n","model_save_path = \"/content/drive/My Drive/Colab Notebooks/final_models/\"\n","model_save_name = \"roberta_sentiment_exc4_weights.pt\"\n","\n","find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"RSL7T2PMSGgi","executionInfo":{"status":"ok","timestamp":1755444589298,"user_tz":-180,"elapsed":949733,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}},"outputId":"05cac7ba-064a-4c50-8b41-d91c308c6f48"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_0.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_0.pt Accuracy: 0.5469\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_1.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_1.pt Accuracy: 0.5924\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_2.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_2.pt Accuracy: 0.5843\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_3.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_3.pt Accuracy: 0.5787\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_4.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_4.pt Accuracy: 0.5700\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_5.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_5.pt Accuracy: 0.5727\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_6.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_6.pt Accuracy: 0.5756\n","Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_7.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_7.pt Accuracy: 0.5753\n","Best model saved at /content/drive/My Drive/Colab Notebooks/final_models/roberta_sentiment_exc4_weights.pt with accuracy 0.5924\n"]}]},{"cell_type":"markdown","source":["**Second Model**\n","\n","find the best model of distilbert-base-uncased-finetuned-sst-2-english"],"metadata":{"id":"wJ08gRMoUPw7"}},{"cell_type":"code","source":["model_folder_path = \"/content/drive/My Drive/Colab Notebooks/models/distilbert_sentiment_balanced_data\"\n","model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n","model_save_path = \"/content/drive/My Drive/Colab Notebooks/final_models/\"\n","model_save_name = \"distilbert_exc4_weights.pt\"\n","\n","find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["cf92ad75151648d487f0d031a659ccb0","83900a71a8de4c6bbf956912b4159dc9","445dff50291c4b789ada1c83999fdaaa","9dec9d8ecb454da28d937ea23bc0df94","3b812a018264475b87ddf2d6a329dcd4","60deb318787f44eeafda242808d1d596","1297671bdf3848ed9372c9d770236d13","601a7e93f2df445d91550fb91d483392","65cc0118e6774b449cfe2ba2a06c919f","084660b783c849b0915f8965186c33ca","63d0f605c96a4652b650a44d4e625b23","629687e86994481ba938fc37690339e3","dcdb6ea81e5645de958dc893fd164755","957b3c548dfc46ea89edbe53cb205e29","7e89ef7c1efa47a79a77526f226e214c","e39dda2a478a4d968196a6f2f4f0f895","d84b46e1f2da4e69962b1e19b0d21dcf","44b6fd0feba246c6a7538131771cfde3","e72c4c7b57ef48a48657f9a1914f9ec8","b0c603fc75894f87aacd4cfabb5e9dee","12af19ba02c5453badee49490795e52f","4978da207d134e19a1a06fb628201ddf","385051742bbf43f6ba4e7413b0247b7e","78b5b82f78634c38aa053becdb626474","78002c44c6fc4b50ac8fa0bae2b4241b","47a79e3b7ba54531bd2d4ef25456bb33","d82a2a7743a748df9f2903ae98295deb","21f6eb2ed5b9419d915e1dd011016df3","2cc93a5c9aa3424493e7f583e3efcdb4","1f690fee1a4846efb265c52232e15485","7b0ac8357dc04949816fbd744ac21645","16f166ea4485494291a1d8a949e4868d","04fa2efb5ab2419cb240270f94a755bc","3d482ec29abc4866893269fa221ca158","82deed60de1c4f28a29daeed0d4f4c15","6953fa3a1f0c4ece9bbf725c679c62f2","27999885d0644b7190ed17ec11fad140","4050421e932646f1840ca28d14f0c0d1","560ac97701ca4db4bc4f8db36b17d2af","f888a4e0947e45ab989a0455e07b5f66","ad07c6ceba4546cb8564252d0fe38330","38783cd321824e8c920d40c7ebcbcd40","dfeb33a06c7842ecae13bc814e33f068","66ca3304fb5c4c24b590bd0552fedf3d"]},"collapsed":true,"id":"v2OLokleS21i","executionInfo":{"status":"ok","timestamp":1755444753097,"user_tz":-180,"elapsed":163689,"user":{"displayName":"ערן טש","userId":"12449389201006934627"}},"outputId":"0d940779-8588-4b54-bd02-318ce90f1382"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf92ad75151648d487f0d031a659ccb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629687e86994481ba938fc37690339e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"385051742bbf43f6ba4e7413b0247b7e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluating best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_0.pt\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d482ec29abc4866893269fa221ca158"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n","- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_0.pt Accuracy: 0.6303\n","Evaluating best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_1.pt\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n","- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n","- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_1.pt Accuracy: 0.6274\n","Best model saved at /content/drive/My Drive/Colab Notebooks/final_models/distilbert_exc4_weights.pt with accuracy 0.6303\n"]}]},{"cell_type":"markdown","source":["<center><h1>END</h1></center>\n"],"metadata":{"id":"wZeiRjjVfxDn"}}]}