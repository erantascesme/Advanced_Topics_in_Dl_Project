{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoyALLr0bNOE"
   },
   "source": [
    "\n",
    "<center><br><font size=6>Final Project</font><br>\n",
    "<font size=5>Advanced Topics in Deep Learning</font><br>\n",
    "<b><font size=4>Part B</font></b>\n",
    "<br><font size=4>Training Models like Excercise 4</font><br><br>\n",
    "Authors: Ido Rappaport & Eran Tascesme\n",
    "</font></center>\n",
    "\n",
    "**Submission Details:**\n",
    "<font size=2>\n",
    "<br>Ido Rappaport, ID: 322891623\n",
    "<br>Eran Tascesme , ID: 205708720 </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1L3bp_8b151"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aB1LkOmnzJ9F"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "from gensim import corpora, models\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    DataCollatorWithPadding,\n",
    "    RobertaForSequenceClassification,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer\n",
    ")\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import evaluate\n",
    "\n",
    "# Other libraries\n",
    "import optuna\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TBDjyqHXzhsG"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BoK9Q14Xzij5",
    "outputId": "991e1901-bda4-43a2-8db9-725e369e64cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBaTf2CrcCqk"
   },
   "source": [
    "**Load 4 CSV Files**\n",
    "1. dirty - the original set from kaggle\n",
    "2. clean - after removing signs and stopwords\n",
    "3. cutted - after removing short/long tweets\n",
    "4. balanced - after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0dYwQ6h5zmyn"
   },
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "\n",
    "drive_path = \"data/\"\n",
    "\n",
    "train_dirty = pd.read_csv(drive_path + \"train_dirty.csv\", encoding=\"ISO-8859-1\")\n",
    "train_clean = pd.read_csv(drive_path + \"train_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "train_cutted = pd.read_csv(drive_path + \"train_cutted.csv\", encoding=\"ISO-8859-1\")\n",
    "train_balanced = pd.read_csv(drive_path + \"train_balanced.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "val_dirty = pd.read_csv(drive_path + \"val_dirty.csv\", encoding=\"ISO-8859-1\")\n",
    "val_clean = pd.read_csv(drive_path + \"val_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "val_cutted = pd.read_csv(drive_path + \"val_cutted.csv\", encoding=\"ISO-8859-1\")\n",
    "val_balanced = val_cutted.copy()  # augmentation is just on the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUgVjKh_cghK"
   },
   "source": [
    "**Tweet Dataset Class**\n",
    "\n",
    "This class is a custom PyTorch Dataset to handle the tweet data. It tokenizes the text and prepares it for use with a transformer model. It includes filtering for empty texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xBYjvXI-0YlF"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        # Ensure 'text' column is string type and filter out any empty strings\n",
    "        self.dataframe = dataframe.copy()\n",
    "        self.dataframe['text'] = self.dataframe['text'].astype(str)\n",
    "        self.dataframe = self.dataframe[self.dataframe['text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "        self.texts = self.dataframe['text'].tolist()\n",
    "        self.labels = self.dataframe['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Add a check for empty text after retrieval (should be rare after filtering in __init__)\n",
    "        if not text or not text.strip():\n",
    "             print(f\"Warning: Empty text found at index {idx}. This should ideally be filtered in __init__.\")\n",
    "\n",
    "             # For robustness, ensure text is string here too, though __init__ should handle it.\n",
    "             if not isinstance(text, str):\n",
    "                 print(f\"Warning: Non-string text found at index {idx}: {text} (type: {type(text)}).\")\n",
    "                 # Option: Convert to string or handle as error\n",
    "                 text = str(text) if text is not None else \"\" # Attempt conversion\n",
    "\n",
    "             if not text.strip():\n",
    "                 return None # Return None if text is still empty after potential conversion\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Ensure the tensors are not empty after encoding\n",
    "        if encoding['input_ids'].nelement() == 0:\n",
    "             print(f\"Warning: Empty encoding for text at index {idx}: '{text}'.\")\n",
    "             return None # Return None if encoding is empty\n",
    "\n",
    "        # Squeeze to remove batch dim (1) so shape is [seq_len]\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs6dRvOWeg8b"
   },
   "source": [
    "**Training Classes and Methods**\n",
    "\n",
    "We chose to train based on accuracy, but we also monitored other metrics such as loss, precision, recall, and F1-score.\n",
    "\n",
    "We used Adam as our optimizer and CrossEntropyLoss as our criterion.\n",
    "\n",
    "Additionally, we observed that freezing layers is done differently for various model types. To maintain generality, we added a model_type variable that allows us to freeze the layers accordingly.\n",
    "\n",
    "We opted for a small number of trials and epochs to save time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XPRm4dNx0buE"
   },
   "outputs": [],
   "source": [
    "def early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, current_val_accuracy, current_val_accuracy_epoch):\n",
    "    early_stop_flag = False\n",
    "    if current_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = current_val_accuracy\n",
    "        best_val_accuracy_epoch = current_val_accuracy_epoch\n",
    "    else:\n",
    "        if current_val_accuracy_epoch - best_val_accuracy_epoch > patience:\n",
    "            early_stop_flag = True\n",
    "    return best_val_accuracy, best_val_accuracy_epoch, early_stop_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FVOGHIIY0eLT"
   },
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(model, project_name, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_accuracy_epoch = 0\n",
    "    early_stop_flag = False\n",
    "    best_model_state = None\n",
    "    print(f\"trail= {trial.number}\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"epoch= {epoch}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train_predictions = 0\n",
    "\n",
    "        for batch in train_loader:  #Iterates over the train_loader, which is a DataLoader object containing batches of training data.\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()   # Reset gradients\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) # Forward pass\n",
    "            logits = outputs.logits   # save the logits (the raw output of the model)\n",
    "            loss = criterion(logits, labels)   # Calculate loss\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update weights using the optimizer\n",
    "\n",
    "            # Accumulate training loss and predictions\n",
    "            train_loss += loss.item() * input_ids.size(0)\n",
    "            total_train_samples += input_ids.size(0)\n",
    "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_loss /= total_train_samples\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        ###  Validation loop  ###\n",
    "        model.eval() # Enable evaluation mode\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val_predictions = 0\n",
    "\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "\n",
    "        with torch.no_grad(): # Disable gradient computation\n",
    "            for batch in val_loader: # iterate on the val_loader's batches\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * input_ids.size(0)\n",
    "                total_val_samples += input_ids.size(0)\n",
    "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        # calculate metrics\n",
    "        val_loss /= total_val_samples\n",
    "        val_accuracy = correct_val_predictions / total_val_samples\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='micro')\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='micro')\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='micro')\n",
    "\n",
    "        # Check for early stopping\n",
    "        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check(patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch)\n",
    "\n",
    "        # Save the best model under the best_model_state parameter\n",
    "        if val_accuracy == best_val_accuracy:\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        # Log metrics to Weights & Biases \n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Precision\": val_precision,\n",
    "            \"Validation Recall\": val_recall,\n",
    "            \"Validation F1\": val_f1})\n",
    "\n",
    "        if early_stop_flag:  # Checks whether the early stopping condition has been met, as indicated by the early_stop_flag\n",
    "            break   \n",
    "\n",
    "    if best_model_state is not None: # Save the best model as a .pt file\n",
    "        base_output_dir = \"models/\"\n",
    "        output_dir = os.path.join(base_output_dir, project_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        sanitized_model_name = model_name.replace(\"/\", \"-\")\n",
    "        file_path = os.path.join(output_dir, f\"best_{sanitized_model_name}_model_trial_{trial.number}.pt\")\n",
    "\n",
    "        torch.save(best_model_state, file_path)\n",
    "\n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5cnZg-qp0oJb"
   },
   "outputs": [],
   "source": [
    "# Objective Function for Optuna\n",
    "def objective(trial, train_df, eval_df, project_name, model_name, autotokenizer, automodelclassification, model_type):\n",
    "    # Hyperparameter suggestions\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-4)\n",
    "    patience = trial.suggest_int(\"patience\", 3, 4)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 2)\n",
    "\n",
    "    train_dataset = TweetDataset(train_df, autotokenizer)\n",
    "    val_dataset = TweetDataset(eval_df, autotokenizer)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        # Filter out None values from the batch\n",
    "        batch = [item for item in batch if item is not None]\n",
    "        if not batch: # Return None if the batch is empty after filtering\n",
    "            return None\n",
    "        input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "        attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "        labels = torch.stack([item['labels'] for item in batch])\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn) # insert into a DataLoader\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn) # insert into a DataLoader\n",
    "\n",
    "    model = automodelclassification.to(device)\n",
    "\n",
    "    if model_type == \"roberta\":\n",
    "        # Freeze all RoBERTa layers\n",
    "        for param in model.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze last `num_layers` encoder layers\n",
    "        for param in model.roberta.encoder.layer[-num_layers:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Unfreeze the classifier head\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif model_type == \"dilbert\":\n",
    "        # Freeze all distilber layers\n",
    "        backbone = model.distilbert\n",
    "        for p in backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        # # Unfreeze last `num_layers` encoder layers\n",
    "        for p in backbone.transformer.layer[-num_layers:].parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        # # Unfreeze the classifier head\n",
    "        if hasattr(model, \"pre_classifier\"):\n",
    "            for p in model.pre_classifier.parameters():\n",
    "                p.requires_grad = True\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Initialize Weights & Biases - the values in the config are the properties of each trial.\n",
    "    wandb.init(project=project_name,\n",
    "               config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"patience\": patience,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"architecture\": model_name,\n",
    "        \"dataset\": \"Corona_NLP\"},\n",
    "        name=f\"trial_{trial.number}\") # The name that will be saved in the W&B platform\n",
    "\n",
    "    # Train the model and get the best validation accuracy\n",
    "    best_val_accuracy = train_model_with_hyperparams(model, project_name, train_loader, val_loader, optimizer, criterion, epochs=6, patience=patience, trial=trial)\n",
    "\n",
    "    wandb.finish() # Finish the Weights & Biases run\n",
    "\n",
    "    return best_val_accuracy # Return best validation acc as the objective to maximize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHl87LbKe6SD"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment\n",
    "\n",
    "We trained the model on 4 Datasets: dirty, clean, cutted and balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5FPWEBR1DO1"
   },
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model_type = \"roberta\"\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "automodelclassification = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyTVYKGY0v6C"
   },
   "outputs": [],
   "source": [
    "project_name = \"roberta_sentiment_dirty_data_exc4\"\n",
    "\n",
    "roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "roberta_sentiment_study.optimize(partial(objective, train_df=train_dirty, eval_df=val_dirty, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFg3q0Ph01up"
   },
   "outputs": [],
   "source": [
    "project_name = \"roberta_sentiment_clean_data_exc4\"\n",
    "\n",
    "roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "roberta_sentiment_study.optimize(partial(objective, train_df=train_clean, eval_df=val_clean, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYdKDRXv07Lh"
   },
   "outputs": [],
   "source": [
    "project_name = \"roberta_sentiment_cutted_data_exc4\"\n",
    "\n",
    "roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "roberta_sentiment_study.optimize(partial(objective, train_df=train_cutted, eval_df=val_cutted, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFRZ3Xna09DD"
   },
   "outputs": [],
   "source": [
    "project_name = \"roberta_sentiment_balanced_data_exc4\"\n",
    "\n",
    "roberta_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "roberta_sentiment_study.optimize(partial(objective, train_df=train_balanced, eval_df=val_clean, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8b_AlBEfYby"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "We trained the model on 4 Datasets: dirty, clean, cutted and balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fORbP8j32nm6"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model_type = \"dilbert\"\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "automodelclassification = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=5,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpIcUyTa21s3"
   },
   "outputs": [],
   "source": [
    "project_name = \"distilbert_sentiment_dirty_data_exc4\"\n",
    "\n",
    "distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "distilber_sentiment_study.optimize(partial(objective, train_df=train_dirty, eval_df=val_dirty, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EG45X6uM29tR"
   },
   "outputs": [],
   "source": [
    "project_name = \"distilbert_sentiment_clean_data_exc4\"\n",
    "\n",
    "distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "distilber_sentiment_study.optimize(partial(objective, train_df=train_clean, eval_df=val_clean, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU0QMlhk3Eob"
   },
   "outputs": [],
   "source": [
    "project_name = \"distilbert_sentiment_cutted_data_exc4\"\n",
    "\n",
    "distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "distilber_sentiment_study.optimize(partial(objective, train_df=train_cutted, eval_df=val_cutted, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUvtX3vD2_qV"
   },
   "outputs": [],
   "source": [
    "project_name = \"distilbert_sentiment_balanced_data_exc4\"\n",
    "\n",
    "distilber_sentiment_study = optuna.create_study(direction=\"maximize\")\n",
    "distilber_sentiment_study.optimize(partial(objective, train_df=train_balanced, eval_df=val_balanced, project_name=project_name, model_name=model_name, autotokenizer=autotokenizer, automodelclassification=automodelclassification, model_type=model_type),\n",
    "               n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POBRlsidPO69"
   },
   "source": [
    "**Choosing the best model for each model type**\n",
    "\n",
    "By looking on W&B we found that the most stable training was on the augmented dataset. Therefore, we will continue with the model trained on this specific set, as it yielded the highest results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "K18bteK4PPT9"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "# Ensure the 'text' column is treated as string type\n",
    "test_data['text'] = test_data['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-atlv3MJSRTv"
   },
   "source": [
    "This `find_and_save_best_model` function iterates through all saved model files (`.pt`) in a specified folder, evaluates each model's accuracy on the test dataset, and saves the model with the highest accuracy to a designated location with a given filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TzODkVEdit-D"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return accuracy_score(true_labels, preds)\n",
    "\n",
    "def find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data, batch_size=16):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    test_dataset = TweetDataset(test_data, tokenizer)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    # Iterate over all .pt files\n",
    "    for file_name in os.listdir(model_folder_path):\n",
    "        if file_name.endswith(\".pt\"):\n",
    "            print(f\"Evaluating {file_name}\")\n",
    "            file_path = os.path.join(model_folder_path, file_name)\n",
    "\n",
    "            # Load model\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_name,\n",
    "                num_labels=5, ignore_mismatched_sizes=True)\n",
    "\n",
    "            state_dict = torch.load(file_path, map_location=device)\n",
    "\n",
    "            # Handle both plain state_dict and dict with 'model_state_dict'\n",
    "            if \"model_state_dict\" in state_dict:\n",
    "                state_dict = state_dict[\"model_state_dict\"]\n",
    "\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(device)\n",
    "\n",
    "            acc = evaluate_model(model, test_loader, device)\n",
    "            print(f\"Model {file_name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_state_dict = state_dict\n",
    "\n",
    "    if best_state_dict is not None:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        save_path = os.path.join(model_save_path, model_save_name)\n",
    "        torch.save(best_state_dict, save_path)\n",
    "        print(f\"Best model saved at {save_path} with accuracy {best_acc:.4f}\")\n",
    "    else:\n",
    "        print(\" No .pt files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xnYkPQkT_5m"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "find the best model of twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RSL7T2PMSGgi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "05cac7ba-064a-4c50-8b41-d91c308c6f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_0.pt Accuracy: 0.5469\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_1.pt Accuracy: 0.5924\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_2.pt Accuracy: 0.5843\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_3.pt Accuracy: 0.5787\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_4.pt Accuracy: 0.5700\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_5.pt Accuracy: 0.5727\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_6.pt Accuracy: 0.5756\n",
      "Evaluating best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_cardiffnlp-twitter-roberta-base-sentiment-latest_model_trial_7.pt Accuracy: 0.5753\n",
      "Best model saved at /content/drive/My Drive/Colab Notebooks/final_models/roberta_sentiment_exc4_weights.pt with accuracy 0.5924\n"
     ]
    }
   ],
   "source": [
    "model_folder_path = \"models/roberta_sentiment_balanced_data\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model_save_path = \"final_models/\"\n",
    "model_save_name = \"roberta_sentiment_exc4_weights.pt\"\n",
    "\n",
    "find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ08gRMoUPw7"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "find the best model of distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "cf92ad75151648d487f0d031a659ccb0",
      "83900a71a8de4c6bbf956912b4159dc9",
      "445dff50291c4b789ada1c83999fdaaa",
      "9dec9d8ecb454da28d937ea23bc0df94",
      "3b812a018264475b87ddf2d6a329dcd4",
      "60deb318787f44eeafda242808d1d596",
      "1297671bdf3848ed9372c9d770236d13",
      "601a7e93f2df445d91550fb91d483392",
      "65cc0118e6774b449cfe2ba2a06c919f",
      "084660b783c849b0915f8965186c33ca",
      "63d0f605c96a4652b650a44d4e625b23",
      "629687e86994481ba938fc37690339e3",
      "dcdb6ea81e5645de958dc893fd164755",
      "957b3c548dfc46ea89edbe53cb205e29",
      "7e89ef7c1efa47a79a77526f226e214c",
      "e39dda2a478a4d968196a6f2f4f0f895",
      "d84b46e1f2da4e69962b1e19b0d21dcf",
      "44b6fd0feba246c6a7538131771cfde3",
      "e72c4c7b57ef48a48657f9a1914f9ec8",
      "b0c603fc75894f87aacd4cfabb5e9dee",
      "12af19ba02c5453badee49490795e52f",
      "4978da207d134e19a1a06fb628201ddf",
      "385051742bbf43f6ba4e7413b0247b7e",
      "78b5b82f78634c38aa053becdb626474",
      "78002c44c6fc4b50ac8fa0bae2b4241b",
      "47a79e3b7ba54531bd2d4ef25456bb33",
      "d82a2a7743a748df9f2903ae98295deb",
      "21f6eb2ed5b9419d915e1dd011016df3",
      "2cc93a5c9aa3424493e7f583e3efcdb4",
      "1f690fee1a4846efb265c52232e15485",
      "7b0ac8357dc04949816fbd744ac21645",
      "16f166ea4485494291a1d8a949e4868d",
      "04fa2efb5ab2419cb240270f94a755bc",
      "3d482ec29abc4866893269fa221ca158",
      "82deed60de1c4f28a29daeed0d4f4c15",
      "6953fa3a1f0c4ece9bbf725c679c62f2",
      "27999885d0644b7190ed17ec11fad140",
      "4050421e932646f1840ca28d14f0c0d1",
      "560ac97701ca4db4bc4f8db36b17d2af",
      "f888a4e0947e45ab989a0455e07b5f66",
      "ad07c6ceba4546cb8564252d0fe38330",
      "38783cd321824e8c920d40c7ebcbcd40",
      "dfeb33a06c7842ecae13bc814e33f068",
      "66ca3304fb5c4c24b590bd0552fedf3d"
     ]
    },
    "id": "v2OLokleS21i",
    "outputId": "0d940779-8588-4b54-bd02-318ce90f1382",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf92ad75151648d487f0d031a659ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629687e86994481ba938fc37690339e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385051742bbf43f6ba4e7413b0247b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_0.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d482ec29abc4866893269fa221ca158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_0.pt Accuracy: 0.6303\n",
      "Evaluating best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_distilbert-distilbert-base-uncased-finetuned-sst-2-english_model_trial_1.pt Accuracy: 0.6274\n",
      "Best model saved at /content/drive/My Drive/Colab Notebooks/final_models/distilbert_exc4_weights.pt with accuracy 0.6303\n"
     ]
    }
   ],
   "source": [
    "model_folder_path = \"models/distilbert_sentiment_balanced_data\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model_save_path = \"final_models/\"\n",
    "model_save_name = \"distilbert_exc4_weights.pt\"\n",
    "\n",
    "find_and_save_best_model(model_folder_path, model_name, model_save_path, model_save_name, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZeiRjjVfxDn"
   },
   "source": [
    "<center><h1>END</h1></center>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04fa2efb5ab2419cb240270f94a755bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "084660b783c849b0915f8965186c33ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1297671bdf3848ed9372c9d770236d13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12af19ba02c5453badee49490795e52f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16f166ea4485494291a1d8a949e4868d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f690fee1a4846efb265c52232e15485": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "21f6eb2ed5b9419d915e1dd011016df3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27999885d0644b7190ed17ec11fad140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfeb33a06c7842ecae13bc814e33f068",
      "placeholder": "",
      "style": "IPY_MODEL_66ca3304fb5c4c24b590bd0552fedf3d",
      "value": "268M/268M[00:03&lt;00:00,87.9MB/s]"
     }
    },
    "2cc93a5c9aa3424493e7f583e3efcdb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "385051742bbf43f6ba4e7413b0247b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78b5b82f78634c38aa053becdb626474",
       "IPY_MODEL_78002c44c6fc4b50ac8fa0bae2b4241b",
       "IPY_MODEL_47a79e3b7ba54531bd2d4ef25456bb33"
      ],
      "layout": "IPY_MODEL_d82a2a7743a748df9f2903ae98295deb"
     }
    },
    "38783cd321824e8c920d40c7ebcbcd40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b812a018264475b87ddf2d6a329dcd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d482ec29abc4866893269fa221ca158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82deed60de1c4f28a29daeed0d4f4c15",
       "IPY_MODEL_6953fa3a1f0c4ece9bbf725c679c62f2",
       "IPY_MODEL_27999885d0644b7190ed17ec11fad140"
      ],
      "layout": "IPY_MODEL_4050421e932646f1840ca28d14f0c0d1"
     }
    },
    "4050421e932646f1840ca28d14f0c0d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "445dff50291c4b789ada1c83999fdaaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_601a7e93f2df445d91550fb91d483392",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65cc0118e6774b449cfe2ba2a06c919f",
      "value": 48
     }
    },
    "44b6fd0feba246c6a7538131771cfde3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47a79e3b7ba54531bd2d4ef25456bb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16f166ea4485494291a1d8a949e4868d",
      "placeholder": "",
      "style": "IPY_MODEL_04fa2efb5ab2419cb240270f94a755bc",
      "value": "232k/?[00:00&lt;00:00,14.1MB/s]"
     }
    },
    "4978da207d134e19a1a06fb628201ddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "560ac97701ca4db4bc4f8db36b17d2af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "601a7e93f2df445d91550fb91d483392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60deb318787f44eeafda242808d1d596": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "629687e86994481ba938fc37690339e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcdb6ea81e5645de958dc893fd164755",
       "IPY_MODEL_957b3c548dfc46ea89edbe53cb205e29",
       "IPY_MODEL_7e89ef7c1efa47a79a77526f226e214c"
      ],
      "layout": "IPY_MODEL_e39dda2a478a4d968196a6f2f4f0f895"
     }
    },
    "63d0f605c96a4652b650a44d4e625b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65cc0118e6774b449cfe2ba2a06c919f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66ca3304fb5c4c24b590bd0552fedf3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6953fa3a1f0c4ece9bbf725c679c62f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad07c6ceba4546cb8564252d0fe38330",
      "max": 267832558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38783cd321824e8c920d40c7ebcbcd40",
      "value": 267832558
     }
    },
    "78002c44c6fc4b50ac8fa0bae2b4241b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f690fee1a4846efb265c52232e15485",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b0ac8357dc04949816fbd744ac21645",
      "value": 1
     }
    },
    "78b5b82f78634c38aa053becdb626474": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21f6eb2ed5b9419d915e1dd011016df3",
      "placeholder": "",
      "style": "IPY_MODEL_2cc93a5c9aa3424493e7f583e3efcdb4",
      "value": "vocab.txt:"
     }
    },
    "7b0ac8357dc04949816fbd744ac21645": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e89ef7c1efa47a79a77526f226e214c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12af19ba02c5453badee49490795e52f",
      "placeholder": "",
      "style": "IPY_MODEL_4978da207d134e19a1a06fb628201ddf",
      "value": "629/629[00:00&lt;00:00,50.7kB/s]"
     }
    },
    "82deed60de1c4f28a29daeed0d4f4c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_560ac97701ca4db4bc4f8db36b17d2af",
      "placeholder": "",
      "style": "IPY_MODEL_f888a4e0947e45ab989a0455e07b5f66",
      "value": "model.safetensors:100%"
     }
    },
    "83900a71a8de4c6bbf956912b4159dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60deb318787f44eeafda242808d1d596",
      "placeholder": "",
      "style": "IPY_MODEL_1297671bdf3848ed9372c9d770236d13",
      "value": "tokenizer_config.json:100%"
     }
    },
    "957b3c548dfc46ea89edbe53cb205e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e72c4c7b57ef48a48657f9a1914f9ec8",
      "max": 629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0c603fc75894f87aacd4cfabb5e9dee",
      "value": 629
     }
    },
    "9dec9d8ecb454da28d937ea23bc0df94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_084660b783c849b0915f8965186c33ca",
      "placeholder": "",
      "style": "IPY_MODEL_63d0f605c96a4652b650a44d4e625b23",
      "value": "48.0/48.0[00:00&lt;00:00,4.50kB/s]"
     }
    },
    "ad07c6ceba4546cb8564252d0fe38330": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0c603fc75894f87aacd4cfabb5e9dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf92ad75151648d487f0d031a659ccb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83900a71a8de4c6bbf956912b4159dc9",
       "IPY_MODEL_445dff50291c4b789ada1c83999fdaaa",
       "IPY_MODEL_9dec9d8ecb454da28d937ea23bc0df94"
      ],
      "layout": "IPY_MODEL_3b812a018264475b87ddf2d6a329dcd4"
     }
    },
    "d82a2a7743a748df9f2903ae98295deb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d84b46e1f2da4e69962b1e19b0d21dcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcdb6ea81e5645de958dc893fd164755": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d84b46e1f2da4e69962b1e19b0d21dcf",
      "placeholder": "",
      "style": "IPY_MODEL_44b6fd0feba246c6a7538131771cfde3",
      "value": "config.json:100%"
     }
    },
    "dfeb33a06c7842ecae13bc814e33f068": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e39dda2a478a4d968196a6f2f4f0f895": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e72c4c7b57ef48a48657f9a1914f9ec8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f888a4e0947e45ab989a0455e07b5f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
