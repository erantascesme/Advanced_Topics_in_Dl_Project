{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvpYI-0WgaUl"
   },
   "source": [
    "\n",
    "<center><br><font size=6>Final Project</font><br>\n",
    "<font size=5>Advanced Topics in Deep Learning</font><br>\n",
    "<b><font size=4>Part B</font></b>\n",
    "<br><font size=4>Training Models like Excercise 5</font><br><br>\n",
    "Authors: Ido Rappaport & Eran Tascesme\n",
    "</font></center>\n",
    "\n",
    "**Submission Details:**\n",
    "<font size=2>\n",
    "<br>Ido Rappaport, ID: 322891623\n",
    "<br>Eran Tascesme , ID: 205708720 </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGXi6ds5gf73"
   },
   "source": [
    "**Import libraries**\n",
    "\n",
    "❗Note the versions of the packages, we have included information in requirements.txt❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITeJ8qym4WFi"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import gc\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "from gensim import corpora, models\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    RobertaForSequenceClassification,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer\n",
    ")\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import evaluate\n",
    "from dataclasses import dataclass\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "# Other libraries\n",
    "import optuna\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Osy-xhh94Xla",
    "outputId": "f7b45a17-ea3b-4be9-8511-7eea51694fea"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03_clmXj4a6r"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRHphkGGg5tB"
   },
   "source": [
    "**Load CSV Files**\n",
    "\n",
    "Following the results from training based on excercise 4, we concluded that we can train solely on the clean, truncated dataset after augmentation. This approach also helps save time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cahbmKSgrY6"
   },
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "\n",
    "drive_path = \"data/\"\n",
    "\n",
    "train_dataset = pd.read_csv(drive_path + \"train_balanced.csv\", encoding=\"ISO-8859-1\")\n",
    "eval_dataset = pd.read_csv(drive_path + \"val_clean.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9aQ2l3xhq8K"
   },
   "source": [
    "**Training Classes and Methods**\n",
    "\n",
    "The function `train_with_optuna_wandb` is designed for training a Hugging Face `transformers` model using hyperparameter optimization with Optuna and experiment tracking with Weights & Biases (W&B). It performs the following steps:\n",
    "\n",
    "*   Sets up W&B for tracking the Optuna trials and the final best model run.\n",
    "*   Initializes the tokenizer and prepares the datasets.\n",
    "*   Defines the model initialization, metric computation, and objective function for Optuna.\n",
    "*   Configures base training arguments for the hyperparameter search.\n",
    "*   Implements a custom callback to log metrics per epoch during Optuna trials to W&B.\n",
    "*   Defines the hyperparameter search space for Optuna.\n",
    "*   Runs the Optuna hyperparameter search to find the best combination of hyperparameters.\n",
    "*   Prints the details of the best trial found by Optuna.\n",
    "*   Logs a summary table of all Optuna trials to W&B.\n",
    "*   Performs a final training run with the best hyperparameters found by Optuna, with W&B logging enabled.\n",
    "*   Saves the trained model with the best hyperparameters.\n",
    "\n",
    "This function provides a **general framework** for hyperparameter tuning and experiment tracking for sequence classification tasks using Hugging Face models, Optuna, and W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3P_OZhW4b-W"
   },
   "outputs": [],
   "source": [
    "def train_with_optuna_wandb(\n",
    "    project_name, model_name, train_dataset, eval_dataset,\n",
    "    num_labels=5, n_trials=5, num_train_epochs=5\n",
    "):\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    # Set W&B environment\n",
    "    os.environ[\"WANDB_PROJECT\"] = project_name\n",
    "    os.environ[\"WANDB_MODE\"] = \"disabled\"  # Disable W&B auto-logging for trials\n",
    "\n",
    "    # Start single W&B run to track all trials\n",
    "    wandb_run = wandb.init(project=project_name, name=\"optuna_search_all_trials\", reinit=True)\n",
    "\n",
    "    # Define custom metrics for step tracking\n",
    "    wandb.define_metric(\"epoch\")\n",
    "    wandb.define_metric(\"eval_accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"train_accuracy\", step_metric=\"epoch\")\n",
    "\n",
    "    # W&B table for final summary\n",
    "    trials_table = wandb.Table(columns=[\n",
    "        \"trial\", \"learning_rate\", \"batch_size\", \"weight_decay\", \"eval_accuracy\", \"train_accuracy\"\n",
    "    ])\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True, batch_size=64)\n",
    "    tokenized_eval = eval_dataset.map(tokenize_function, batched=True, batch_size=64)\n",
    "\n",
    "    # Accuracy metric\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def model_init():\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_labels, ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions = eval_pred.predictions.argmax(axis=-1)\n",
    "        labels = eval_pred.label_ids\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    def compute_objective(metrics):\n",
    "        return metrics[\"eval_accuracy\"]\n",
    "\n",
    "    # Base training args (for Optuna search)\n",
    "    base_training_args = TrainingArguments(\n",
    "        output_dir=f\"{project_name}/temp_run\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_strategy=\"epoch\",\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        report_to=[],  # Disable W&B logging during search\n",
    "        logging_dir=f\"{project_name}/logs\",\n",
    "    )\n",
    "\n",
    "    # Callback for logging per epoch\n",
    "    class WandbOptunaCallback(TrainerCallback):\n",
    "        def on_epoch_end(self, args, state, control, **kwargs):\n",
    "            train_metrics = trainer.evaluate(eval_dataset=tokenized_train, metric_key_prefix=\"train\")\n",
    "            eval_metrics = trainer.evaluate(eval_dataset=tokenized_eval, metric_key_prefix=\"eval\")\n",
    "\n",
    "            train_acc = train_metrics.get(\"train_accuracy\", None)\n",
    "            eval_acc = eval_metrics.get(\"eval_accuracy\", None)\n",
    "\n",
    "            # Log per epoch with trial info\n",
    "            wandb.log({\n",
    "                \"eval_accuracy\": eval_acc,\n",
    "                \"train_accuracy\": train_acc,\n",
    "                \"epoch\": state.epoch,\n",
    "                \"trial\": state.trial_name,\n",
    "            })\n",
    "\n",
    "            # Add final metrics to summary table\n",
    "            if state.epoch + 1 == num_train_epochs:\n",
    "                trials_table.add_data(\n",
    "                    state.trial_name,\n",
    "                    state.trial_params.get(\"learning_rate\"),\n",
    "                    state.trial_params.get(\"per_device_train_batch_size\"),\n",
    "                    state.trial_params.get(\"weight_decay\"),\n",
    "                    eval_acc,\n",
    "                    train_acc\n",
    "                )\n",
    "\n",
    "    # Trainer for Optuna trials\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=base_training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[WandbOptunaCallback()]\n",
    "    )\n",
    "\n",
    "    def optuna_hp_space(trial):\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "            \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [64, 128]),\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-4, 0.3),\n",
    "        }\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    best_run = trainer.hyperparameter_search(\n",
    "        direction=\"maximize\",\n",
    "        backend=\"optuna\",\n",
    "        hp_space=optuna_hp_space,\n",
    "        n_trials=n_trials,\n",
    "        compute_objective=compute_objective,\n",
    "        study_name=\"transformers_optuna_study\",\n",
    "        storage=f\"sqlite:///{project_name}/optuna_trials.db\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    print(\"Best trial:\", best_run)\n",
    "\n",
    "    # Log summary table\n",
    "    wandb.log({\"optuna_trials\": trials_table})\n",
    "\n",
    "    # Finish main W&B run\n",
    "    wandb.finish()\n",
    "\n",
    "    # Re-enable W&B for final training run\n",
    "    os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "    # Final training args (W&B enabled)\n",
    "    final_training_args = TrainingArguments(\n",
    "        output_dir=f\"{project_name}/best_model_run\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_strategy=\"epoch\",\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=best_run.hyperparameters[\"learning_rate\"],\n",
    "        per_device_train_batch_size=best_run.hyperparameters[\"per_device_train_batch_size\"],\n",
    "        weight_decay=best_run.hyperparameters[\"weight_decay\"],\n",
    "        report_to=[\"wandb\"],\n",
    "        logging_dir=f\"{project_name}/logs\",\n",
    "        run_name=\"final_best_model\"\n",
    "    )\n",
    "\n",
    "    # Final model trainer\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=final_training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Save best model\n",
    "    best_model_path = f\"{project_name}/best_model\"\n",
    "    trainer.save_model(best_model_path)\n",
    "    print(f\"Best model saved to {best_model_path}\")\n",
    "\n",
    "    wandb.finish()\n",
    "    return best_model_path, best_run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqZ1N_6cj6mj"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment\n",
    "\n",
    "the function above save the best model automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bel9PMt4i_r"
   },
   "outputs": [],
   "source": [
    "best_model_path, best_roberta_run = train_with_optuna_wandb(\n",
    "    project_name=\"roberta_sentiment_cutted_data_exc5\",\n",
    "    model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    num_labels=5,\n",
    "    n_trials=5,\n",
    "    num_train_epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deJh2tAsj7Ul"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "the function above save the best model automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEKluamo4jv-"
   },
   "outputs": [],
   "source": [
    "best_model_distil_path, best_distil_run = train_with_optuna_wandb(\n",
    "    project_name=\"distilbert_sentiment_5_cutted_data_exc5\",\n",
    "    model_name=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    num_labels=5,\n",
    "    n_trials=5,\n",
    "    num_train_epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugyvd-6h1DZT"
   },
   "source": [
    "**Improving the selected models**\n",
    "\n",
    "To improve model training, we are trying to increase the hyperparameter space and the number of studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTXbD9Z-RIgP"
   },
   "outputs": [],
   "source": [
    "# --- Load CSV files from your Drive ---\n",
    "drive_path = \"data/\"\n",
    "\n",
    "train_df = pd.read_csv(drive_path + \"train_balanced.csv\", encoding=\"ISO-8859-1\")\n",
    "eval_df = pd.read_csv(drive_path + \"val_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "test_df = pd.read_csv(drive_path + \"test_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "for df in [train_df, eval_df, test_df]:\n",
    "    df['text'] = df['text'].fillna('').astype(str)\n",
    "\n",
    "# For consistency, rename the label column to 'labels'\n",
    "train_df = train_df.rename(columns={'label': 'labels'})\n",
    "eval_df = eval_df.rename(columns={'label': 'labels'})\n",
    "test_df = test_df.rename(columns={'label': 'labels'})\n",
    "\n",
    "\n",
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TF1ZAsaQu9c"
   },
   "outputs": [],
   "source": [
    "def run_hyperparameter_search_and_train(\n",
    "    project_name, model_name, train_dataset, eval_dataset, test_dataset,\n",
    "    num_labels=5, n_trials=12, num_train_epochs=5\n",
    "):\n",
    "    # 1. Set W&B Project Environment Variable\n",
    "    os.environ[\"WANDB_PROJECT\"] = project_name\n",
    "\n",
    "    # 2. Tokenizer and Data Preparation\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # 3. Model Initializer (for fresh model in each trial)\n",
    "    def model_init():\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            ignore_mismatched_sizes=True   # Useful for re-initializing head\n",
    "        )\n",
    "\n",
    "    # 4. Metrics Computation\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # 5. Define the Optuna Objective Function\n",
    "    def objective(trial):\n",
    "        # A. Suggest hyperparameters\n",
    "        hp = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 5e-5, log=True),\n",
    "            \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [64, 128]),\n",
    "            \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2]),\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.3),\n",
    "            \"optim\": trial.suggest_categorical(\"optim\", [\"adamw_torch\", \"adafactor\"]),\n",
    "            \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\"]),\n",
    "        }\n",
    "\n",
    "        # B. Define Training Arguments for this specific trial\n",
    "        # Each trial will be a new run in W&B\n",
    "        trial_run_name = f\"trial-{trial.number}\"\n",
    "        output_dir = f\"./results/{trial_run_name}\"\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            run_name=trial_run_name,\n",
    "            # Core training parameters\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
    "            per_device_eval_batch_size=64,\n",
    "            gradient_accumulation_steps=hp[\"gradient_accumulation_steps\"],\n",
    "            learning_rate=hp[\"learning_rate\"],\n",
    "            weight_decay=hp[\"weight_decay\"],\n",
    "            optim=hp[\"optim\"],\n",
    "            lr_scheduler_type=hp[\"lr_scheduler_type\"],\n",
    "            fp16=True if device == \"cuda\" else False, # Enable mixed precision\n",
    "            # Evaluation and logging\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            report_to=\"wandb\",\n",
    "            # Efficiency\n",
    "            save_total_limit=1, # Only keep the best checkpoint\n",
    "            push_to_hub=False,\n",
    "        )\n",
    "\n",
    "        # C. Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_eval,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "        )\n",
    "\n",
    "        # D. Train and return metric for Optuna\n",
    "        trainer.train()\n",
    "        eval_metrics = trainer.evaluate()\n",
    "\n",
    "        # E. Clean up to free memory\n",
    "        del trainer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return eval_metrics[\"eval_accuracy\"]\n",
    "\n",
    "    # 6. Run Hyperparameter Search\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"sentiment-analysis-optimization\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_hyperparameters = study.best_trial.params\n",
    "    print(\"🏆 Best Hyperparameters Found 🏆\")\n",
    "    print(best_hyperparameters)\n",
    "\n",
    "    # 7. Train the Final Model with Best Hyperparameters\n",
    "    print(\"🚀 Training final model with best hyperparameters...\")\n",
    "    final_training_args = TrainingArguments(\n",
    "        output_dir=\"./results/best-model\",\n",
    "        run_name=\"final-best-model-run\",\n",
    "        # Use best hyperparameters\n",
    "        **best_hyperparameters,\n",
    "        # Other fixed settings\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_eval_batch_size=64,\n",
    "        fp16=True if device == \"cuda\" else False,\n",
    "        # Evaluation and logging\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        report_to=\"wandb\",\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "\n",
    "    final_trainer = Trainer(\n",
    "        model=model_init(), # Re-initialize the model\n",
    "        args=final_training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    )\n",
    "\n",
    "    final_trainer.train()\n",
    "\n",
    "    # 8. Evaluate the Best Model on the Test Set\n",
    "    print(\"\\n🧪 Evaluating the final best model on the test dataset...\")\n",
    "    test_results = final_trainer.evaluate(eval_dataset=tokenized_test)\n",
    "\n",
    "    print(\"✅ Final Test Results ✅\")\n",
    "    print(f\"Test Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"Test Loss: {test_results['eval_loss']:.4f}\")\n",
    "\n",
    "    # Log test results to the final W&B run\n",
    "    wandb.log({\"test_accuracy\": test_results[\"eval_accuracy\"], \"test_loss\": test_results[\"eval_loss\"]})\n",
    "\n",
    "    # End the final W&B run\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "    # 9. Save the Final Model\n",
    "    best_model_path = f\"{project_name}/best_model\"\n",
    "    final_trainer.save_model(best_model_path)\n",
    "\n",
    "    # Define the path and filename for the weights\n",
    "    weights_path = f\"final_models/{project_name}.pt\"\n",
    "    weights_dir = os.path.dirname(weights_path)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "    # Get the state dictionary from the trained model\n",
    "    model_weights = final_trainer.model.state_dict()\n",
    "\n",
    "    # Save the state dictionary to the specified .pt file\n",
    "    torch.save(model_weights, weights_path)\n",
    "\n",
    "    print(f\"Best model saved to {best_model_path}\")\n",
    "\n",
    "    return best_model_path, best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHza9YL493aW"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment\n",
    "\n",
    "the function above save the best model automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cca72d94ec544b3c983afc4460cbc982",
      "5981d6a7c01645b386bcfd18026de6c7",
      "30cef7f6aad24be6824a62e8ef64d125",
      "d836fbd8cac94a0d937b2c32a8fd0324",
      "1923f1240fb1463c8d1a8ce5bcb5098e",
      "10f0214b87204138a8c5b8231bf9c366",
      "2d51bb92c30d4fa3a0482c6fa95f719b",
      "3afa8bf491a4458793cdd30bc5c4cb29",
      "0be7fe8ef9f24fd68d7104e2a284be85",
      "7b8f8eb949e8453d944c7244cef083a8",
      "bb039d2c379f402d8c1ccc26e8755d39",
      "91f3ba8dba394df88408711eb8878f7d",
      "e59f652c157443fcba1578a0a8eb2cee",
      "7c923a882f4143d28bbdbd8d0a382129",
      "8d39c6653bdb494baaed3d83ee3c0cc2",
      "a1e1b2f12bb14e74af006a02b38101ee",
      "c8b5adadfe624c699e09181b2166fda9",
      "c51ef83ff1454fe2ba7de3f1cd4a7347",
      "52438b96f8084684a2f4b4c8bdf2e3ea",
      "c34951da86964056b78fc2bbff06c022",
      "bc2935d526544f1096ec3b68d57fa2de",
      "547664c8789d4edcbbc1eacce2896f9d",
      "07ff59327c07431ba7efffeb30916dd3",
      "9654a69f86494d1ab33881cc32ad9ff7",
      "44fbbe5c54ba42968efd644fa99e82a5",
      "f312761f10e04160b1331cde7560df01",
      "f71a197e91104cce91112fe38bb53ea9",
      "fa3b2686b25646ad8f536553918ac01d",
      "5e6582c1c1114adb923a03b7ad173ecf",
      "f08906699ab849b4815fd312b7aab6f1",
      "484e82d4f8364ab08d604fad5c4c4fbe",
      "cb8fdb7fa03c4b079be49193eaab7852",
      "98250babb8a644a384e093d4caa36a01"
     ]
    },
    "id": "rr-E-FYCYltr",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3e1497b5-83a2-4ce1-8f47-2fa7cb121944"
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"roberta_sentiment_exc5_improved\"\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "N_TRIALS = 12  # Number of Optuna trials to run\n",
    "N_EPOCHS = 5  # Number of epochs for each training run\n",
    "\n",
    "# --- Run the experiment ---\n",
    "best_model_path, best_params = run_hyperparameter_search_and_train(\n",
    "    project_name=PROJECT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    num_labels=5,\n",
    "    n_trials=N_TRIALS,\n",
    "    num_train_epochs=N_EPOCHS\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNsc6F7U9_cf"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "the function above save the best model automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "da86fabfca264f92a78df51b5f99e441",
      "74a1be1e43a843a5bd0d699924b10438",
      "bb4cf14b3fc64cee96c66127d2fdaba4",
      "729a73cc0e244a2b9d6823d891c3dbf3",
      "d5f34eff142e48f1943c690252cc2b6a",
      "a7ed8583dd104a718bda68b055715b04",
      "00d656d60dcd4b8cbae1f4338e4ad3c3",
      "0f609822f5ff4194b16b5185a8eea5a6",
      "fbd54e1c3b034ba8bcb572e1ca3fd581",
      "80e2bcdaf6524064b89114de4666bb86",
      "eb3018a9b01d41909776841f574bd8fc",
      "ac37afd611ec46229fb4b162fb82b830",
      "82a9e4e25faf4493b0a9dd286400776f",
      "8e82f6af7eb14fc2bf90099021c838e0",
      "baac0a6c24534f55a414254b3e2545e4",
      "ec95ffcb707647f39b5ba2d9d6f554b3",
      "f60af0e8c8b84f6bb246225ac41a8804",
      "d6594ee4dbc645169e420218619c1828",
      "628806334d6f44a7beee6da8cc8fe870",
      "76a781d0ca9744468ff21076b9f833a6",
      "1e5fb6e2fc0542fca75fdc8bc3cbc6cb",
      "5c255a1025a2425990eee2c759208ccd",
      "9dce6a32ebbb43e99d70b27a84b15c0c",
      "4693732d383a46ae8eb393734b5ddf39",
      "d9cc61f23fa347bdbfd8d4ea5e87b4d7",
      "2ea86d7561b6427689b20be15e37c358",
      "3c2a33cfd4c2422daa09a5da1e6e6b51",
      "b42b0dfbb18b46549646149bd2a86156",
      "6d9bc6605ab04d919af8a960773b03df",
      "322259a04e91492cbd18fd05bb3955c1",
      "11fa275c7b2d4d88b69fdf4207cd061f",
      "b6882b1c4b5047b79c49c0899ae1f381",
      "8193ebb960b24b52a54e239df26bcc27"
     ]
    },
    "id": "ApubzhpdSDc3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6e3b1094-e298-4be1-ec52-dfb5ccf6443f"
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "PROJECT_NAME = \"distilbert_exc5_improved\"\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "N_TRIALS = 12 # Number of Optuna trials to run\n",
    "N_EPOCHS = 5 # Number of epochs for each training run\n",
    "\n",
    "# --- Run the experiment ---\n",
    "best_model_path, best_params = run_hyperparameter_search_and_train(\n",
    "    project_name=PROJECT_NAME,\n",
    "    model_name=MODEL_NAME,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    num_labels=5,\n",
    "    n_trials=N_TRIALS,\n",
    "    num_train_epochs=N_EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fieYqmU28wag"
   },
   "source": [
    "<center><h1>END</h1></center>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
