{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WMGxrvUtebT"
   },
   "source": [
    "<center><br><font size=6>Final Project</font><br>\n",
    "<font size=5>Advanced Topics in Deep Learning</font><br>\n",
    "<b><font size=4>Part B</font></b>\n",
    "<br><font size=4>Load Final Models</font><br><br>\n",
    "Authors: Ido Rappaport & Eran Tascesme\n",
    "</font></center>\n",
    "\n",
    "**Submission Details:**\n",
    "<font size=2>\n",
    "<br>Ido Rappaport, ID: 322891623\n",
    "<br>Eran Tascesme , ID: 205708720 </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGFqouBeRlMB"
   },
   "source": [
    "**Import libraries**\n",
    "\n",
    "❗Note the versions of the packages, we have included information in requirements.txt❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "54mTHFBatr6e"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    normalized_mutual_info_score,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    DataCollatorWithPadding,\n",
    "    RobertaForSequenceClassification,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer\n",
    ")\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from peft import PeftModel\n",
    "import evaluate\n",
    "\n",
    "# Other libraries\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl6qqnn4t08m"
   },
   "source": [
    "**Load CSV Files**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jP_yVbtqt0ge"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "path_dir = \"final_models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbTCmSkBR8pG"
   },
   "source": [
    "**Load Models**\n",
    "\n",
    "Load the models and create a list containing all of them. Each model type has its own specific loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qtMCuQH5SAa6"
   },
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Et3zl8yqSDka"
   },
   "outputs": [],
   "source": [
    "# function that load the Base Models who trained by exc4 and exc5 without compression (kivutz)\n",
    "def load_base_model(model_name, base_weights_path):\n",
    "\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "  )\n",
    "  state_dict = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "  model.load_state_dict(state_dict)\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  return model, tokenizer\n",
    "\n",
    "\n",
    "# function that load the pruned and distilled models\n",
    "def load_compressed_model(save_model_path, device=\"cpu\"):\n",
    "    model_path = os.path.join(save_model_path, \"model.pt\")\n",
    "    model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# function that load the quantized models\n",
    "def load_quantized_model(model_name, quantized_model_path):\n",
    "  q_state_path = os.path.join(quantized_model_path, \"model.pt\")\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  # Rebuild the same base architecture\n",
    "  loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "  )\n",
    "\n",
    "  # Apply the same dynamic quantization to convert Linear -> quantized Linear\n",
    "  loaded_model = torch.quantization.quantize_dynamic(\n",
    "      loaded_model, {nn.Linear}, dtype=torch.qint8\n",
    "  )\n",
    "\n",
    "  # Now load the quantized weights (keys will match)\n",
    "  loaded_model.load_state_dict(torch.load(q_state_path, map_location=\"cpu\"))\n",
    "  loaded_model.eval()\n",
    "\n",
    "  return loaded_model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8r4ybVoSGvP"
   },
   "source": [
    "**Base Models**\n",
    "\n",
    "The models who trained by exc4 and exc5 without compression (kivutz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5-oYRjbSERD",
    "outputId": "d5ace12a-0737-4888-c015-75f292d485f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "base_weights_path = \"/content/drive/My Drive/Colab Notebooks/final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"roberta_sentiment_exc4\", model, tokenizer))\n",
    "\n",
    "base_weights_path = \"/content/drive/My Drive/Colab Notebooks/final_models/roberta_sentiment_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"roberta_sentiment_exc5\", model, tokenizer))\n",
    "\n",
    "# distilbert\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "base_weights_path = \"/content/drive/My Drive/Colab Notebooks/final_models/distilbert_exc4_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"distilbert_exc4\", model, tokenizer))\n",
    "\n",
    "base_weights_path = \"/content/drive/My Drive/Colab Notebooks/final_models/distilbert_weights.pt\"\n",
    "model, tokenizer = load_base_model(model_name, base_weights_path)\n",
    "model_list.append((\"distilbert_exc5\", model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6iZ_TPMSKtf"
   },
   "source": [
    "**Pruned & Distilled Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2dvplpWxSL94"
   },
   "outputs": [],
   "source": [
    "models_pathes = [\"roberta_exc4_pruned\", \"roberta_pruned\", \"distilbert_exc4_pruned\", \"distilbert_pruned\",\n",
    "                 \"distilroberta_exc4-base\", \"distilroberta-base\", \"tinybert_exc4\", \"tinybert\"]\n",
    "\n",
    "\n",
    "for model_path in models_pathes:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "    model, tokenizer = load_compressed_model(save_model_path, device=\"cpu\")\n",
    "\n",
    "    model_list.append((model_path, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIF65gxTSMU0"
   },
   "source": [
    "**Quantized Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbdVBpBOSMo9",
    "outputId": "bf9bb326-458e-4714-e0a8-93767cf584fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "models_pathes = [\"roberta_sentiment_exc4_quantized\", \"roberta_sentiment_quantized\"]\n",
    "\n",
    "for model_path in models_pathes:\n",
    "  quantized_model_path = os.path.join(path_dir, model_path)\n",
    "  model, tokenizer = load_quantized_model(model_name, quantized_model_path)\n",
    "\n",
    "  model_list.append((model_path, model, tokenizer))\n",
    "\n",
    "#distilbert\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "models_pathes = [\"distilbert_exc4_quantized\", \"distilbert_quantized\"]\n",
    "\n",
    "for model_path in models_pathes:\n",
    "  quantized_model_path = os.path.join(path_dir, model_path)\n",
    "  model, tokenizer = load_quantized_model(model_name, quantized_model_path)\n",
    "\n",
    "  model_list.append((model_path, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg5ypT99d0Up"
   },
   "source": [
    "**LoRA Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bey1qE7ed0Dk",
    "outputId": "adcbf1d3-4690-466c-a1cd-e00bf188bbfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#roberta\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "lora_list = [\"roberta_sentiment_exc4_LoRA\", \"roberta_sentiment_exc5_LoRA\"]\n",
    "\n",
    "for model_path in lora_list:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "\n",
    "    base_model_reload = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "    lora_model_reload = PeftModel.from_pretrained(base_model_reload, save_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "\n",
    "    model_list.append((model_path, lora_model_reload, tokenizer))\n",
    "\n",
    "\n",
    "#distilbert\n",
    "lora_list = [\"distilbert_exc4_LoRA\", \"distilbert_exc5_LoRA\"]\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "for model_path in lora_list:\n",
    "    save_model_path = os.path.join(path_dir, model_path)\n",
    "\n",
    "    base_model_reload = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "    lora_model_reload = PeftModel.from_pretrained(base_model_reload, save_model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_model_path)\n",
    "\n",
    "    model_list.append((model_path, lora_model_reload, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Plho-VSSRDc"
   },
   "source": [
    "**Evaluation**\n",
    "\n",
    "Evaluate all models and calculate a final score for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T0k6lhmJSRVu"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_metrics(model, tokenizer, test_data, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Compute metrics for a single model on test data.\"\"\"\n",
    "    # check if the model is quantized and move it to the cpu/gpu .\n",
    "    is_quantized = any(\n",
    "        isinstance(m, nn.quantized.dynamic.Linear) or isinstance(m, nn.quantized.Linear)\n",
    "        for m in model.modules()\n",
    "    )\n",
    "    if is_quantized:\n",
    "      device = \"cpu\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # store the texts and labels\n",
    "    texts = test_data['text'].tolist()\n",
    "    labels = torch.tensor(test_data['label'].tolist()).to(device)\n",
    "\n",
    "    # start calculate the metrics. time, acc, f1, num_parmas and more.\n",
    "    start_time = time.time()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = [str(t) for t in texts[i:i+batch_size]]\n",
    "            encodings = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "            outputs = model(**encodings)\n",
    "\n",
    "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())    # store the preds\n",
    "    runtime = time.time() - start_time\n",
    "\n",
    "    accuracy = accuracy_score(labels.cpu().numpy(), all_preds)\n",
    "    f1 = f1_score(labels.cpu().numpy(), all_preds, average='macro')\n",
    "\n",
    "    mcc = matthews_corrcoef(labels.cpu().numpy(), all_preds)\n",
    "    nit = normalized_mutual_info_score(labels.cpu().numpy(), all_preds)\n",
    "\n",
    "    conf_matrix = confusion_matrix(labels.cpu().numpy(), all_preds)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    nonzero_params = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'nit': nit,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'runtime_sec': runtime,\n",
    "        'total_params': total_params,\n",
    "        'nonzero_params': nonzero_params\n",
    "    }\n",
    "\n",
    "def evaluate_and_score_models(model_list, test_data, weights=None, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluate multiple HuggingFace models and compute a relative weighted score.\n",
    "\n",
    "    Args:\n",
    "        models: list of (name, model, tokenizer)\n",
    "        test_data: pd.DataFrame with 'text' and 'label'\n",
    "        weights: dict with weights for metrics\n",
    "        batch_size: evaluation batch size\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with metrics and final weighted score\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'accuracy': 0.4, 'mcc': 0.2, 'nit': 0.2,'runtime': 0.1, 'params': 0.05, 'nonzero_params': 0.05}\n",
    "\n",
    "    all_metrics = {}\n",
    "\n",
    "    # Step 1: compute metrics for all models\n",
    "    for name, model, tokenizer in model_list:\n",
    "      print(f\"Evaluating {name}...\")\n",
    "      try:\n",
    "          metrics = evaluate_model_metrics(model, tokenizer, test_data, batch_size=batch_size)\n",
    "          all_metrics[name] = metrics\n",
    "      except Exception as e:\n",
    "          print(f\"Error evaluating {name}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_metrics).T\n",
    "\n",
    "    # Step 2: min-max scale each metric (higher is better for final score)\n",
    "    df_scaled = df.copy()\n",
    "\n",
    "    # For metrics where lower is better (runtime, total_params, nonzero_params)\n",
    "    for col in ['runtime_sec', 'total_params', 'nonzero_params']:\n",
    "        col_normalization = col + \"_norm\"\n",
    "        df_scaled[col_normalization] = 1 / ((df[col] - df[col].min()) / (df[col].max() - df[col].min() + 1e-8) + 0.5)\n",
    "\n",
    "    # Step 3: compute final weighted score\n",
    "    df_scaled['final_score'] = (\n",
    "        weights['accuracy'] * df_scaled['accuracy'] +\n",
    "        weights['mcc'] * df_scaled['mcc'] +\n",
    "        weights['nit'] * df_scaled['nit'] +\n",
    "        weights['runtime'] * df_scaled['runtime_sec_norm'] +\n",
    "        weights['params'] * df_scaled['total_params_norm'] +\n",
    "        weights['nonzero_params'] * df_scaled['nonzero_params_norm']\n",
    "    )\n",
    "\n",
    "    # Sort by final score\n",
    "    df_scaled = df_scaled.sort_values(by='final_score', ascending=False)\n",
    "\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBJ-X-A8Se6L",
    "outputId": "c8bf467b-05e9-438b-8eab-b5d5984ec1b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc5...\n",
      "Evaluating distilbert_exc4...\n",
      "Evaluating distilbert_exc5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_exc4_pruned...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_pruned...\n",
      "Evaluating distilbert_exc4_pruned...\n",
      "Evaluating distilbert_pruned...\n",
      "Evaluating distilroberta_exc4-base...\n",
      "Evaluating distilroberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinybert_exc4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tinybert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4_quantized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_quantized...\n",
      "Evaluating distilbert_exc4_quantized...\n",
      "Evaluating distilbert_quantized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc4_LoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating roberta_sentiment_exc5_LoRA...\n",
      "Evaluating distilbert_exc4_LoRA...\n",
      "Evaluating distilbert_exc5_LoRA...\n",
      "Index(['accuracy', 'f1', 'mcc', 'nit', 'conf_matrix', 'runtime_sec',\n",
      "       'total_params', 'nonzero_params', 'runtime_sec_norm',\n",
      "       'total_params_norm', 'nonzero_params_norm', 'final_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# start evaluation\n",
    "evaluation_df = evaluate_and_score_models(model_list, test_data)\n",
    "print(evaluation_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "PalZZYqiSgzK",
    "outputId": "4e7e9450-af0c-49e2-9e75-2d6605c502f0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"evaluation_df[['accuracy', 'f1', 'mcc', 'nit', 'runtime_sec', 'total_params', 'final_score']]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.28014744602422326,\n        \"max\": 0.7501316482359136,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.7474986835176408,\n          0.28751974723538704,\n          0.37519747235387046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.110437733353587,\n        \"max\": 0.7612903087775653,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.7574652628383564,\n          0.11690586109995986,\n          0.3303155223698454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mcc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.028135414190325864,\n        \"max\": 0.6827471922960378,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.6782609989316429,\n          0.044334050322732715,\n          0.2010745759200516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nit\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.019529906043015143,\n        \"max\": 0.5003034985403744,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.4934889849441867,\n          0.03347061316622304,\n          0.13257473048962415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime_sec\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.8579695224761963,\n        \"max\": 36.07610058784485,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.310286521911621,\n          2.40474271774292,\n          4.640961408615112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_params\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 14351813,\n        \"max\": 125538826,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          23854080,\n          82122245,\n          66957317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_score\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.390406931241167,\n        \"max\": 0.8306005939589489,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.8306005939589489,\n          0.4164810635569473,\n          0.44810732568544626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f339d2f7-f824-478c-95f2-f993fd7eb685\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>mcc</th>\n",
       "      <th>nit</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_params</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilbert_pruned</th>\n",
       "      <td>0.747499</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.493489</td>\n",
       "      <td>2.310287</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.830601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc5</th>\n",
       "      <td>0.750132</td>\n",
       "      <td>0.76129</td>\n",
       "      <td>0.682747</td>\n",
       "      <td>0.500303</td>\n",
       "      <td>2.323985</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.824053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_quantized</th>\n",
       "      <td>0.744866</td>\n",
       "      <td>0.75528</td>\n",
       "      <td>0.675633</td>\n",
       "      <td>0.492854</td>\n",
       "      <td>18.578208</td>\n",
       "      <td>23854080</td>\n",
       "      <td>0.802134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc5</th>\n",
       "      <td>0.748289</td>\n",
       "      <td>0.75888</td>\n",
       "      <td>0.681719</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>4.422121</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.768788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_quantized</th>\n",
       "      <td>0.73802</td>\n",
       "      <td>0.748513</td>\n",
       "      <td>0.668393</td>\n",
       "      <td>0.480219</td>\n",
       "      <td>36.076101</td>\n",
       "      <td>39037440</td>\n",
       "      <td>0.730098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_pruned</th>\n",
       "      <td>0.61901</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>0.518997</td>\n",
       "      <td>0.350883</td>\n",
       "      <td>2.316815</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.718768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4</th>\n",
       "      <td>0.630332</td>\n",
       "      <td>0.642991</td>\n",
       "      <td>0.533828</td>\n",
       "      <td>0.346945</td>\n",
       "      <td>2.320484</td>\n",
       "      <td>66957317</td>\n",
       "      <td>0.715712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_quantized</th>\n",
       "      <td>0.602159</td>\n",
       "      <td>0.613666</td>\n",
       "      <td>0.494164</td>\n",
       "      <td>0.322283</td>\n",
       "      <td>18.413398</td>\n",
       "      <td>23854080</td>\n",
       "      <td>0.675111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinybert</th>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.386043</td>\n",
       "      <td>0.316721</td>\n",
       "      <td>0.206525</td>\n",
       "      <td>0.85797</td>\n",
       "      <td>14351813</td>\n",
       "      <td>0.667367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinybert_exc4</th>\n",
       "      <td>0.373354</td>\n",
       "      <td>0.331221</td>\n",
       "      <td>0.288318</td>\n",
       "      <td>0.194163</td>\n",
       "      <td>0.920501</td>\n",
       "      <td>14351813</td>\n",
       "      <td>0.64513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilroberta-base</th>\n",
       "      <td>0.537915</td>\n",
       "      <td>0.544353</td>\n",
       "      <td>0.439142</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>2.345366</td>\n",
       "      <td>82122245</td>\n",
       "      <td>0.631798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilroberta_exc4-base</th>\n",
       "      <td>0.532122</td>\n",
       "      <td>0.53957</td>\n",
       "      <td>0.429216</td>\n",
       "      <td>0.263544</td>\n",
       "      <td>2.340314</td>\n",
       "      <td>82122245</td>\n",
       "      <td>0.626002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4</th>\n",
       "      <td>0.592417</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.48801</td>\n",
       "      <td>0.306697</td>\n",
       "      <td>4.912364</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.625502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_pruned</th>\n",
       "      <td>0.548183</td>\n",
       "      <td>0.464587</td>\n",
       "      <td>0.431959</td>\n",
       "      <td>0.38172</td>\n",
       "      <td>4.411105</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.62416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4_quantized</th>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.552913</td>\n",
       "      <td>0.415666</td>\n",
       "      <td>0.258233</td>\n",
       "      <td>35.912775</td>\n",
       "      <td>39037440</td>\n",
       "      <td>0.555741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc4_LoRA</th>\n",
       "      <td>0.375197</td>\n",
       "      <td>0.330316</td>\n",
       "      <td>0.201075</td>\n",
       "      <td>0.132575</td>\n",
       "      <td>4.640961</td>\n",
       "      <td>125538826</td>\n",
       "      <td>0.448107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_exc4_pruned</th>\n",
       "      <td>0.339389</td>\n",
       "      <td>0.273564</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.098568</td>\n",
       "      <td>4.389313</td>\n",
       "      <td>124649477</td>\n",
       "      <td>0.435552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc4_LoRA</th>\n",
       "      <td>0.28752</td>\n",
       "      <td>0.116906</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>2.404743</td>\n",
       "      <td>67699210</td>\n",
       "      <td>0.416481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_exc5_LoRA</th>\n",
       "      <td>0.280147</td>\n",
       "      <td>0.110438</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.01953</td>\n",
       "      <td>2.389061</td>\n",
       "      <td>67699210</td>\n",
       "      <td>0.407655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta_sentiment_exc5_LoRA</th>\n",
       "      <td>0.308057</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0.094354</td>\n",
       "      <td>0.085948</td>\n",
       "      <td>4.663688</td>\n",
       "      <td>125538826</td>\n",
       "      <td>0.390407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f339d2f7-f824-478c-95f2-f993fd7eb685')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f339d2f7-f824-478c-95f2-f993fd7eb685 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f339d2f7-f824-478c-95f2-f993fd7eb685');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-6928dd3b-485b-4ccc-a555-1cfc6ec54e3e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6928dd3b-485b-4ccc-a555-1cfc6ec54e3e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-6928dd3b-485b-4ccc-a555-1cfc6ec54e3e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                  accuracy        f1       mcc       nit  \\\n",
       "distilbert_pruned                 0.747499  0.757465  0.678261  0.493489   \n",
       "distilbert_exc5                   0.750132   0.76129  0.682747  0.500303   \n",
       "distilbert_quantized              0.744866   0.75528  0.675633  0.492854   \n",
       "roberta_sentiment_exc5            0.748289   0.75888  0.681719  0.498854   \n",
       "roberta_sentiment_quantized        0.73802  0.748513  0.668393  0.480219   \n",
       "distilbert_exc4_pruned             0.61901  0.633854  0.518997  0.350883   \n",
       "distilbert_exc4                   0.630332  0.642991  0.533828  0.346945   \n",
       "distilbert_exc4_quantized         0.602159  0.613666  0.494164  0.322283   \n",
       "tinybert                          0.406793  0.386043  0.316721  0.206525   \n",
       "tinybert_exc4                     0.373354  0.331221  0.288318  0.194163   \n",
       "distilroberta-base                0.537915  0.544353  0.439142  0.271259   \n",
       "distilroberta_exc4-base           0.532122   0.53957  0.429216  0.263544   \n",
       "roberta_sentiment_exc4            0.592417    0.6065   0.48801  0.306697   \n",
       "roberta_pruned                    0.548183  0.464587  0.431959   0.38172   \n",
       "roberta_sentiment_exc4_quantized  0.538968  0.552913  0.415666  0.258233   \n",
       "roberta_sentiment_exc4_LoRA       0.375197  0.330316  0.201075  0.132575   \n",
       "roberta_exc4_pruned               0.339389  0.273564    0.1888  0.098568   \n",
       "distilbert_exc4_LoRA               0.28752  0.116906  0.044334  0.033471   \n",
       "distilbert_exc5_LoRA              0.280147  0.110438  0.028135   0.01953   \n",
       "roberta_sentiment_exc5_LoRA       0.308057  0.194544  0.094354  0.085948   \n",
       "\n",
       "                                 runtime_sec total_params final_score  \n",
       "distilbert_pruned                   2.310287     66957317    0.830601  \n",
       "distilbert_exc5                     2.323985     66957317    0.824053  \n",
       "distilbert_quantized               18.578208     23854080    0.802134  \n",
       "roberta_sentiment_exc5              4.422121    124649477    0.768788  \n",
       "roberta_sentiment_quantized        36.076101     39037440    0.730098  \n",
       "distilbert_exc4_pruned              2.316815     66957317    0.718768  \n",
       "distilbert_exc4                     2.320484     66957317    0.715712  \n",
       "distilbert_exc4_quantized          18.413398     23854080    0.675111  \n",
       "tinybert                             0.85797     14351813    0.667367  \n",
       "tinybert_exc4                       0.920501     14351813     0.64513  \n",
       "distilroberta-base                  2.345366     82122245    0.631798  \n",
       "distilroberta_exc4-base             2.340314     82122245    0.626002  \n",
       "roberta_sentiment_exc4              4.912364    124649477    0.625502  \n",
       "roberta_pruned                      4.411105    124649477     0.62416  \n",
       "roberta_sentiment_exc4_quantized   35.912775     39037440    0.555741  \n",
       "roberta_sentiment_exc4_LoRA         4.640961    125538826    0.448107  \n",
       "roberta_exc4_pruned                 4.389313    124649477    0.435552  \n",
       "distilbert_exc4_LoRA                2.404743     67699210    0.416481  \n",
       "distilbert_exc5_LoRA                2.389061     67699210    0.407655  \n",
       "roberta_sentiment_exc5_LoRA         4.663688    125538826    0.390407  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df[['accuracy', 'f1', 'mcc', 'nit', 'runtime_sec', 'total_params', 'final_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2YLn2-884Dr"
   },
   "source": [
    "<center><h1>END</h1></center>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "011b082537ca40cc9f001a9ecb417150": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ce6d0b573045cf94c697d73664b793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "132b638de7b54d63ab7f59b8ef7f97a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d30d7bc1e244ee89d990f696278c46d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e21347367064dd2b4b8e32cd3ac948e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ff6182374c5403297f5cd0e67a98b0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48a1b44306ac4339bf547db45452905f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "4a58443311f84dcb8873ceaa82386220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c8569c2302641a3896e04eca26d2716",
       "IPY_MODEL_635b08f4d23b4107984758b9d9abd0bf",
       "IPY_MODEL_856b19f367a542c0a939af0a85222689"
      ],
      "layout": "IPY_MODEL_8a1b7313da7b4966a630c5a0332ffe5d"
     }
    },
    "605d7c42c6d54d21906c0a8fa15a1058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "635b08f4d23b4107984758b9d9abd0bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_011b082537ca40cc9f001a9ecb417150",
      "max": 629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_605d7c42c6d54d21906c0a8fa15a1058",
      "value": 629
     }
    },
    "673cad9e688f4060974464df72e3663e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7840f2c5cad34566a6f01f025d1a93c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_982f11f1b779456f950c7e77bcbcb796",
      "placeholder": "​",
      "style": "IPY_MODEL_c6e9babebe5d49b7b9504a424fc3940e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "7c8569c2302641a3896e04eca26d2716": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecb41a290efb4ed7890f289e8d9b1d9e",
      "placeholder": "​",
      "style": "IPY_MODEL_fe4213350390437eb8cc0a7442f6cfac",
      "value": "config.json: 100%"
     }
    },
    "8191b5069db34fb98a5012f4bec90aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48a1b44306ac4339bf547db45452905f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e800f6ddb4a444ab9dacb6ef976d8fae",
      "value": 1
     }
    },
    "856b19f367a542c0a939af0a85222689": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ff6182374c5403297f5cd0e67a98b0b",
      "placeholder": "​",
      "style": "IPY_MODEL_f01ee8c5ca13453fb54486df8a03bae2",
      "value": " 629/629 [00:00&lt;00:00, 77.5kB/s]"
     }
    },
    "85facf5f48244ddebf2475e1f7b3530a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7840f2c5cad34566a6f01f025d1a93c2",
       "IPY_MODEL_fd1801af21ef4baf93ee40aa1603b7bf",
       "IPY_MODEL_9dcabb9cf97142a8874c929fd6fc0dee"
      ],
      "layout": "IPY_MODEL_c6b1f646d12d42a493cc34ccf1e6d5bf"
     }
    },
    "8a1b7313da7b4966a630c5a0332ffe5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92416a94833a4fc48b95a0794cac4227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9630ecb76a0d46b9aed453c6332cea8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec1fc9fa806344d58b27071b665bfd39",
      "placeholder": "​",
      "style": "IPY_MODEL_980df6a941334ca28d44fe03d0a95331",
      "value": "model.safetensors: 100%"
     }
    },
    "980df6a941334ca28d44fe03d0a95331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "982f11f1b779456f950c7e77bcbcb796": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dcabb9cf97142a8874c929fd6fc0dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_673cad9e688f4060974464df72e3663e",
      "placeholder": "​",
      "style": "IPY_MODEL_3e21347367064dd2b4b8e32cd3ac948e",
      "value": " 48.0/48.0 [00:00&lt;00:00, 4.33kB/s]"
     }
    },
    "a0db8cf5880548f694c3bb87cd52c910": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a14e41092fab4cfe9a3f3cfa6dc34e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c04be2c2385f437cafd026f227cc516f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c16b192206814e52a9ab3d7a506bafa1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6b1f646d12d42a493cc34ccf1e6d5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e9babebe5d49b7b9504a424fc3940e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cec858cb70cf439c88eaee9d545b418b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a14e41092fab4cfe9a3f3cfa6dc34e02",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f24bd2cf2c4b0d92a4bc917e1a4e38",
      "value": " 268M/268M [00:01&lt;00:00, 153MB/s]"
     }
    },
    "d3b466db3a4d4260822d31465949a3f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc5af28496cc452b9a25d542ee4a9b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9630ecb76a0d46b9aed453c6332cea8f",
       "IPY_MODEL_f93463a1f0be4810868e6f541f257ad9",
       "IPY_MODEL_cec858cb70cf439c88eaee9d545b418b"
      ],
      "layout": "IPY_MODEL_c16b192206814e52a9ab3d7a506bafa1"
     }
    },
    "e7d816c566c84c03a80f8f2c686d69e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fff6f223d42e445b9c4a956091a957ee",
       "IPY_MODEL_8191b5069db34fb98a5012f4bec90aeb",
       "IPY_MODEL_ebc9af464ef44b418c7c37b29f214ff1"
      ],
      "layout": "IPY_MODEL_d3b466db3a4d4260822d31465949a3f8"
     }
    },
    "e800f6ddb4a444ab9dacb6ef976d8fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e89b8b5f4e6340f7a0f5d5257e23778e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebc9af464ef44b418c7c37b29f214ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d30d7bc1e244ee89d990f696278c46d",
      "placeholder": "​",
      "style": "IPY_MODEL_132b638de7b54d63ab7f59b8ef7f97a1",
      "value": " 232k/? [00:00&lt;00:00, 18.1MB/s]"
     }
    },
    "ec1fc9fa806344d58b27071b665bfd39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb41a290efb4ed7890f289e8d9b1d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01ee8c5ca13453fb54486df8a03bae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7f24bd2cf2c4b0d92a4bc917e1a4e38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f93463a1f0be4810868e6f541f257ad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0db8cf5880548f694c3bb87cd52c910",
      "max": 267832558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10ce6d0b573045cf94c697d73664b793",
      "value": 267832558
     }
    },
    "fd1801af21ef4baf93ee40aa1603b7bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c04be2c2385f437cafd026f227cc516f",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92416a94833a4fc48b95a0794cac4227",
      "value": 48
     }
    },
    "fe1655958eca43fabc99ee72c4d0a581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe4213350390437eb8cc0a7442f6cfac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fff6f223d42e445b9c4a956091a957ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe1655958eca43fabc99ee72c4d0a581",
      "placeholder": "​",
      "style": "IPY_MODEL_e89b8b5f4e6340f7a0f5d5257e23778e",
      "value": "vocab.txt: "
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
