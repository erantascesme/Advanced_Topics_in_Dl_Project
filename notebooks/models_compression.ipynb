{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh90vSLVlYfN"
   },
   "source": [
    "<center><br><font size=6>Final Project</font><br>\n",
    "<font size=5>Advanced Topics in Deep Learning</font><br>\n",
    "<b><font size=4>Part B</font></b>\n",
    "<br><font size=4>Models Compression</font><br><br>\n",
    "Authors: Ido Rappaport & Eran Tascesme\n",
    "</font></center>\n",
    "\n",
    "**Submission Details:**\n",
    "<font size=2>\n",
    "<br>Ido Rappaport, ID: 322891623\n",
    "<br>Eran Tascesme , ID: 205708720 </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLHMaeh2l7jd"
   },
   "source": [
    "**Import libraries**\n",
    "\n",
    "❗Note the versions of the packages, we have included information in requirements.txt❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnkVFywC8Xp-",
    "outputId": "4cbd0281-bb07-408c-9c56-ef9a0b34d770"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "from gensim import corpora, models\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    set_seed,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    DataCollatorWithPadding,\n",
    "    RobertaForSequenceClassification,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer\n",
    ")\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "import evaluate\n",
    "\n",
    "# Other libraries\n",
    "import optuna\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hAWhdg68jVv"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBxAy_TBnanS"
   },
   "source": [
    "**Load CSV Files**\n",
    "\n",
    "Based on the results, the best-performing models were those trained on the clean, truncated dataset after augmentation. Therefore, we will proceed using this dataset and these specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EASCZ8wDJPdL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_balanced.csv\", encoding=\"ISO-8859-1\")\n",
    "test_data = pd.read_csv(\"data/test_clean.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gld6m2E0omJV"
   },
   "source": [
    "<h2>First Compression Method: <u><b>Quantization</b></u>.</h2>\n",
    "In this section, we will perform quantization on the two selected models.\n",
    "\n",
    " `QuantizeModel`\n",
    "\n",
    "This function takes a base model and its weights and applies dynamic quantization to reduce the model's size and potentially speed up inference. It performs the following steps:\n",
    "\n",
    "1.  Loads the tokenizer and the base model with pre-trained weights.\n",
    "2.  Applies dynamic quantization, converting specified layers (like `Linear` layers) to a lower precision (e.g., 8-bit integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhoW2IU_WAeK"
   },
   "outputs": [],
   "source": [
    "def QuantizeModel(base_weights_path, quantized_model_path, model_name):\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Load base model and weights\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "    )\n",
    "    state_dict = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Quantize\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model, {nn.Linear}, dtype=torch.qint8\n",
    "    )\n",
    "    quantized_model.eval()\n",
    "\n",
    "    os.makedirs(quantized_model_path, exist_ok=True)\n",
    "\n",
    "    q_state_path = os.path.join(quantized_model_path, \"model.pt\")\n",
    "    torch.save(quantized_model.state_dict(), q_state_path)\n",
    "\n",
    "    # Save a tiny meta file so you remember what to reconstruct\n",
    "    with open(os.path.join(quantized_model_path, \"meta.txt\"), \"w\") as f:\n",
    "        f.write(f\"model_name={model_name}\\nnum_labels={5}\\nquantized_layers=Linear\\n\")\n",
    "\n",
    "    print(f\"✅ Quantized model saved at {quantized_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0cKx6xtqa0b"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHD2u8cnVINd"
   },
   "source": [
    "from excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OcoIQ4io0Pc",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a77d49e4-bf35-4f14-8322-efc5bbf3a6df"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "quantized_model_path = \"final_models/roberta_sentiment_exc4_quantized\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "QuantizeModel(base_weights_path, quantized_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA1tNptbVFz7"
   },
   "source": [
    "from excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdV2AdKwVEI2",
    "outputId": "33b66118-d256-4c12-a5d1-bb24f0230227"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_weights.pt\"\n",
    "quantized_model_path = \"final_models/roberta_sentiment_quantized\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "QuantizeModel(base_weights_path, quantized_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lv6XZ2GRqbrg"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-E9rDbyVVOq"
   },
   "source": [
    "from excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "53068530a33e4f57a638b4a3b0d90816",
      "dd60a43c142e44b7bd4954ca8fdb225b",
      "b338c2eb4e854383a5fa252040f264e6",
      "3589c31e521e4678849150489b9244a8",
      "36d5468f9f024cf89089c1d9bf27a2ad",
      "d12062d8eebb42808606db66f6e71f75",
      "30c48ff1f4f546238598ef31087c1bf3",
      "e9e84671d79644e2a480ddccf38e6f04",
      "b46b54c48dcd4ca791853481c135e396",
      "5d697b2392fb4a85aa2c9a007a8ee6ab",
      "85955604055d44a58765511ee3d59138",
      "9a317acd4a284594aaef1a2d4a824858",
      "8ba46dc04a924521b2b040e4cbaa7bb0",
      "58558885d25942cdac920fb0539ea4ea",
      "bb2d8a49db704d8dae9bdfc13310a2ef",
      "df299ee1f09a4813b9943333b515650c",
      "35a1c7ee14014aaaa9229f5ef2b2d73d",
      "a6bb3e5991844fd6bc30ef9a048489eb",
      "0e6d12094dd2439a9c40c392033a02ac",
      "5d2fccdbbb1549898166bb90210bab57",
      "3c73bedf076241e59c69e0123a6055ec",
      "ab4e4ef294b34664898f0866685d1ee0",
      "44842a9a10ec4d5a9a1fa6a7ea2d601a",
      "b624f7dfe888464d94479d5ecf7241fa",
      "fe3ca04a4aa342c6b58a2f591c6c15bb",
      "d8d4f1083b404cea98000341a365abe8",
      "fb17c99c07b844519641948a384ac994",
      "e3609114bad9432e85121c509aa0e095",
      "80e3b0ddf188415bb48cbd7e988e5590",
      "ea68e5e75df14ec7947c607423e35aee",
      "e559c9cc8674416e8930cc33e42a29d2",
      "c491993a5d5747ec89e935fc51b6dadc",
      "b1358bd79f1a4d1684a51646376fe743",
      "2ded348fe7d54836ba2c7932cab5078f",
      "7183f3be15b64b3e90cab517aee06cfc",
      "938c200da3ef4110a71769cecfb0f6c2",
      "b2cd091ebd3d411498f7feb36ce439ff",
      "98e8310167864fd3bd7a48bc8b537e76",
      "0f06673e76424e2b96ee4e476031c065",
      "7eada33454d242519a64b68cc2b83b6b",
      "1d70368a345f4d81a56efdd12e0c5afd",
      "24b186b2990149819fe1c2e98c762ddd",
      "a6ea3e332f90491eba129cedbc1c3080",
      "41b54b58cb4e4dee8855f2883753b7e7"
     ]
    },
    "id": "jp6hyBqKVSzE",
    "outputId": "ed8ed2d3-db06-45b9-fa42-5bd91b87d09d"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_exc4_weights.pt\"\n",
    "quantized_model_path = \"final_models/distilbert_exc4_quantized\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "QuantizeModel(base_weights_path, quantized_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enGwhe7YVU4h"
   },
   "source": [
    "from excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrek18Jzpd9A",
    "outputId": "112ec73b-0a81-4eea-fec7-bef72d51d8f2"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_weights.pt\"\n",
    "quantized_model_path = \"final_models/distilbert_quantized\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "QuantizeModel(base_weights_path, quantized_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMvpTSU9q1uR"
   },
   "source": [
    "<h2>Second Compression Method: <u><b>Pruning</b></u>.</h2>\n",
    "In this section, we will perform 40% pruning on the two selected models.\n",
    "\n",
    " `PruneModel`\n",
    "\n",
    "This function takes a base model and its weights and applies unstructured L1 pruning to reduce the number of parameters. It performs the following steps:\n",
    "\n",
    "1.  Loads the tokenizer and the base model with pre-trained weights.\n",
    "2.  Applies L1 unstructured pruning to the `weight` of all `Linear` layers, setting a percentage of the smallest weights to zero.\n",
    "3.  Removes the pruning reparameterization to make the pruned weights permanent.\n",
    "4.  Saves the state dictionary of the pruned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtVAMfl7JI5W"
   },
   "outputs": [],
   "source": [
    "def PruneModel(base_weights_path, pruned_model_path, model_name, prune_amount=0.4):\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Load base model and weights\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=5, ignore_mismatched_sizes=True\n",
    "    )\n",
    "    state_dict = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Apply pruning\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name=\"weight\", amount=prune_amount)\n",
    "\n",
    "    # Remove pruning reparameterization so pruned weights are stored directly\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.remove(module, \"weight\")\n",
    "\n",
    "    # Count parameters (still the same, but many are zero)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    num_nonzero = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    print(f\"Total params: {num_params}, Non-zero params: {num_nonzero}\")\n",
    "\n",
    "    # === Save with PyTorch + tokenizer ===\n",
    "    os.makedirs(pruned_model_path, exist_ok=True)\n",
    "    torch.save(model, os.path.join(pruned_model_path, \"model.pt\"))\n",
    "    tokenizer.save_pretrained(pruned_model_path)\n",
    "\n",
    "    print(f\"✅ Pruned model saved to {pruned_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAmRX1Atra--"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrzNyAKEVeb_"
   },
   "source": [
    "from excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2Za6O_-Vd9W",
    "outputId": "d2bee53d-1601-46ab-9a50-4359e40a057e"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "pruned_model_path = \"final_models/roberta_exc4_pruned\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "PruneModel(base_weights_path, pruned_model_path, model_name, prune_amount=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4AFb2vFVe12"
   },
   "source": [
    "from excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRG8kGkorag6",
    "outputId": "5a6017a6-6137-4e56-db7c-93de3cd7f0a4"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_weights.pt\"\n",
    "pruned_model_path = \"final_models/roberta_pruned\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "PruneModel(base_weights_path, pruned_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXT6cW91rbjY"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOZCERAwViZO"
   },
   "source": [
    "from excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PS3J-PljViO0",
    "outputId": "fb1b9756-d7a6-4df4-a2cc-f4c05cce7819"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_exc4_weights.pt\"\n",
    "pruned_model_path = \"final_models/distilbert_exc4_pruned\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "PruneModel(base_weights_path, pruned_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsuHssY9ViC6"
   },
   "source": [
    "from excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qdFpYZvrZbZ",
    "outputId": "56b58cff-0fb0-4967-8d77-981f24908536"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_weights.pt\"\n",
    "pruned_model_path = \"final_models/distilbert_pruned\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "PruneModel(base_weights_path, pruned_model_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zag0mJRtyf5"
   },
   "source": [
    "<h2>Third Compression Method: <u><b>Distillation</b></u>.</h2>\n",
    "In this section, we will perform Distillation with two different models on the two selected models.\n",
    "\n",
    "`DistillationTrainer`\n",
    "\n",
    "This custom trainer class extends the standard HuggingFace `Trainer` to perform knowledge distillation. It incorporates a teacher model to guide the training of a student model. Key aspects include:\n",
    "\n",
    "1.  **Initialization:** Takes a `teacher_model`, temperature for softening logits, and an alpha parameter to balance the hard (cross-entropy) and soft (KL divergence) losses.\n",
    "2.  **`compute_loss` Method:** Overrides the standard loss computation to include both:\n",
    "    *   A **hard loss** (cross-entropy) between the student's predictions and the true labels.\n",
    "    *   A **soft loss** (KL divergence) between the softened logits of the student and the teacher.\n",
    "    The final loss is a weighted sum of these two losses, controlled by the `alpha` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL11DhPt9ZeV"
   },
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, teacher_model=None, alpha=0.5, temperature=2.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self.teacher.eval()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs_student = model(**inputs)\n",
    "        student_logits = outputs_student.logits\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(**inputs)\n",
    "            teacher_logits = outputs_teacher.logits\n",
    "\n",
    "        # Hard loss\n",
    "        loss_ce = F.cross_entropy(student_logits, labels)\n",
    "\n",
    "        # Soft loss\n",
    "        loss_kl = F.kl_div(\n",
    "            F.log_softmax(student_logits / self.temperature, dim=-1),\n",
    "            F.softmax(teacher_logits / self.temperature, dim=-1),\n",
    "            reduction=\"batchmean\"\n",
    "        ) * (self.temperature ** 2)\n",
    "\n",
    "        loss = self.alpha * loss_ce + (1.0 - self.alpha) * loss_kl\n",
    "        return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWdknsWQuXv_"
   },
   "source": [
    "`freeze_student_layers`\n",
    "\n",
    "This function is a helper used in the distillation process to selectively freeze the layers of the student model during training. It aims to prevent the initial layers of the student from changing significantly and focuses the training on the later layers and the classifier head. Specifically, it:\n",
    "\n",
    "1.  Sets `requires_grad` to `False` for the parameters of the student's base model (all layers except the classifier).\n",
    "2.  Explicitly sets `requires_grad` to `True` for the parameters of the **last transformer block** and the **classifier** layer, allowing only these parts of the model to be trained during distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC4AZRIV9eEo"
   },
   "outputs": [],
   "source": [
    "def freeze_student_layers(student):\n",
    "    for param in student.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # last transformer block\n",
    "    if hasattr(student.base_model, \"encoder\"):\n",
    "        last_layer = student.base_model.encoder.layer[-1]\n",
    "        for param in last_layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # classifier\n",
    "    for param in student.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    print(\"✅ Froze all layers except last block + classifier\")\n",
    "    return student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fmxg5Rf8un1A"
   },
   "source": [
    "`distill_student`\n",
    "\n",
    "This function orchestrates the knowledge distillation process to train a student model using a pre-trained teacher model. Key steps include:\n",
    "\n",
    "1.  **Data Loading and Preparation:** Loads training and test data and tokenizes it using the student model's tokenizer.\n",
    "2.  **Model Initialization:** Loads the teacher model (optionally with custom weights) and the student model.\n",
    "3.  **Layer Freezing:** Freezes most layers of the student model, except for the last transformer block and the classifier, to focus training.\n",
    "4.  **Trainer Setup:** Initializes a `DistillationTrainer` with the student and teacher models, training arguments, and datasets.\n",
    "5.  **Training:** Starts the distillation training process.\n",
    "6.  **Saving:** Saves the distilled student model and its tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy8hwVce9Pd-"
   },
   "outputs": [],
   "source": [
    "# ==== General Function ====\n",
    "def distill_student(base_weights_path, teacher_name, student_name, output_dir, num_labels,\n",
    "                    train_data, test_data, text_col=\"text\", label_col=\"label\"):\n",
    "    \"\"\"\n",
    "    Perform teacher-student distillation training.\n",
    "\n",
    "    Args:\n",
    "        base_weights_path (str or None): Optional .pt checkpoint for teacher (PyTorch state_dict).\n",
    "        teacher_name (str): HuggingFace model name for teacher.\n",
    "        student_name (str): HuggingFace model name for student.\n",
    "        output_dir (str): Path to save distilled student.\n",
    "        num_labels (int): Number of labels for classification.\n",
    "        train_data (pd.DataFrame or Dataset): Raw training data with 'text' and 'label'.\n",
    "        test_data (pd.DataFrame or Dataset): Raw test data with 'text' and 'label'.\n",
    "        text_col (str): Name of text column.\n",
    "        label_col (str): Name of label column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pandas → Dataset if needed\n",
    "    if not isinstance(train_data, Dataset):\n",
    "        train_data = Dataset.from_pandas(train_data)\n",
    "    if not isinstance(test_data, Dataset):\n",
    "        test_data = Dataset.from_pandas(test_data)\n",
    "\n",
    "    # Load teacher\n",
    "    teacher = AutoModelForSequenceClassification.from_pretrained(teacher_name, num_labels=num_labels, ignore_mismatched_sizes=True)\n",
    "\n",
    "    # If custom weights provided, load them into teacher\n",
    "    if base_weights_path is not None:\n",
    "        checkpoint = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "        teacher.load_state_dict(checkpoint, strict=False)\n",
    "        print(f\"✅ Loaded teacher weights from {base_weights_path}\")\n",
    "\n",
    "    # Load student\n",
    "    student = AutoModelForSequenceClassification.from_pretrained(student_name, num_labels=num_labels, ignore_mismatched_sizes=True)\n",
    "    student = freeze_student_layers(student)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(student_name)\n",
    "\n",
    "    # Tokenization function\n",
    "    def tokenize_fn(batch):\n",
    "      return tokenizer(\n",
    "          [str(x) for x in batch[text_col]],\n",
    "          truncation=True,\n",
    "          padding=\"max_length\",\n",
    "          max_length=128\n",
    "      )\n",
    "\n",
    "    tokenized_train = train_data.map(tokenize_fn, batched=True)\n",
    "    tokenized_test = test_data.map(tokenize_fn, batched=True)\n",
    "\n",
    "    tokenized_train = tokenized_train.rename_column(label_col, \"labels\")\n",
    "    tokenized_test = tokenized_test.rename_column(label_col, \"labels\")\n",
    "\n",
    "    tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    # Training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "      logits, labels = eval_pred\n",
    "      preds = logits.argmax(axis=1)\n",
    "      acc = accuracy_score(labels, preds)\n",
    "      f1 = f1_score(labels, preds, average=\"macro\")\n",
    "      return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "    # Trainer\n",
    "    trainer_distill = DistillationTrainer(\n",
    "        model=student,\n",
    "        teacher_model=teacher,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer_distill.train()\n",
    "\n",
    "    # === Save ===\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    torch.save(student, os.path.join(output_dir, \"model.pt\"))\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    print(f\"✅ Weights saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH2rlA5Cu2Q6"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment\n",
    "\n",
    "student: distilroberta-base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daAjgCLIV3vK"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913,
     "referenced_widgets": [
      "9a5c3a42e8984fce816ff066b2f4d78f",
      "fd1d98e0ec324adea6b203101612e786",
      "393919925eb741d6aa7a49d7cb3f6688",
      "2047bb4cfd1046f890e2929df6704309",
      "adea4e80fe8247928d943dfd84717ae8",
      "540ae9bec9604b718f21f44bf3fea7d5",
      "2ee3f35c514c4d7bb9c6d7ec6fd3b0b6",
      "8ff94ec3fa304c199382f17c24f99054",
      "36cffda7e5c74a55b69c72bfc60676d1",
      "52ed870b35cf4e10bd83565aaf75f730",
      "e175f30042174e5fbbb5c10363e71572",
      "06b13ae23774408da36640331cb3999b",
      "58f48a85bf894a678b973423c56a2f02",
      "948e3ea06d1a4cb686252a2d995efa2b",
      "20636b9431e841978a0bc3d4f9b92c8e",
      "613307b38c754f039a28f1894f36c453",
      "c0b6a82d8d904d53bf9a4f9db983637b",
      "3eda30417a4744b38be295a6ee365640",
      "6a4ebf50b8ff4d67a53150fcefbc91f2",
      "6cf1dea742a54a64bd3f547f49c43486",
      "db5fc79fd2f84ad8a33d8f30f08294b7",
      "d17d5bb493474e27ad6f3270ea11c015",
      "3b3d7e1978ef43ec90e4d900a121eb75",
      "3e6b1ebe28824fa3915de6968216d705",
      "1fff2a71733b4d2fbfbb058d5225ee47",
      "a7605cb9f765484e97529d957e6d3819",
      "eec27423b8c844439f3045468dbeee30",
      "4439e578c2df46e2a2f351082fca4c8b",
      "07968caedede45c08a88ec8724bff6a4",
      "626164e3961d4ad1b925c8e31eea9066",
      "d9ed6692abac41e89c2c1ef4a5c8ee6b",
      "a91ae20e5f2a40379d9ee93e55cfd202",
      "a6ac6863e69547109698c22e31681f93",
      "46525336c0494c2c8144db935fedb2f8",
      "e4fa7863eaa143e8aef432ae268f644c",
      "0293f4b63ad645c0b128babb417425d2",
      "96dfed37cd094db9a7c3c85482651a9c",
      "7c7c1d11147944379076792951175c57",
      "f722b26b88cf47a7a04f3e53b74efd30",
      "317fbc1c1368476e9848dfc53d62542b",
      "1c15fc4b896c40ae9128f9ea8c72dfc7",
      "d1a21110973a4e729df0ec9aaff9c8e5",
      "c23c843949414c0fb63eda59b508249f",
      "e7b7e5bbe08e4f0fa14ed1e21a75affa",
      "d1d753559ab94458af74c84524fc5984",
      "c2cbc60a52e94e21bd46e1cedfaff75c",
      "bb7509eb03a942e6989b5cc543f2d422",
      "6015a9141ca9460397d012bb01c3769a",
      "7b5077b4e97f4000a0af03cfd04e08b2",
      "8b5eef89f80e4f2fa21da9285eb3d4c6",
      "ebc69e2071ef4387aa8ae57ca5dfd9db",
      "3735e5aa81884ecebb4e1f1e4adbc6b5",
      "fc77b3aa1dd54239baf331c7721ff939",
      "8ea9f386702946e8a886f257c2929cde",
      "b7d13641327f4918a2c519297e606aea",
      "80c662ba8b6746b7bb6b7fc3505be387",
      "64188925f19b4a7ab07186199a5ba4d5",
      "ea3624949ca0497b9d0233576c7d2f81",
      "5a8ef660af6040989257ecaae755cad0",
      "fd2c0a48dfdc4e5286914f34056cd6e9",
      "f4bdba50687b4e66b4eb0c336ce4340e",
      "2f6fb1ed2ef54ed7a082472f1760486a",
      "3c263cfa73ee48b992950fb6fc2f4cdd",
      "2ee1b4cb8a6b49dab20a3e1d79e6443e",
      "1a057cbcc6b947b99a830fa56a2bdb3d",
      "7e549037750c42bf8885e7a8d7ff70f0",
      "626c6c147ba34c6f8f4abd0bd288ed57",
      "8be5921b1df5439f8605321a7a6d9d87",
      "d1f34bc994bf42baae52cbf6312cc008",
      "16649790c9584758a5d7142d6bc12fb2",
      "d25294a0e3a04febb42aae4adfdbd996",
      "8c88b8b0a1574b259160f91404be765f",
      "3f3849b8614b4f74b1ad2420c3dd34eb",
      "d06be2204fe04355bad41a43ad98146f",
      "ffd0d0d5847e479491d0c058d3fe17b7",
      "c6cb7a10528e49b5a7c82cf312de7bfa",
      "019231a3eaf9426e945dd898b7340068",
      "18f1f8bf74824e91bf596f49f87204f9",
      "b54c9d971e584e509e92e608c405e4da",
      "dab1966b3be640b69e6298a0f59f4004",
      "6589d685a5dd45589516dd1b72042751",
      "0895ac0f66884bcfb53a73d80c22cf8c",
      "e21787afe0494834b01b1c18a84a6224",
      "10345ee84f2b482fbd840a421044217b",
      "164b540756ed44faa57355acfe5fbec5",
      "d1885b49bcc34956a4f1c7be673e1c3b",
      "becb5bc7999b4b8f971a2eb3f34d0fcf",
      "ed798eb188db448da16842e7e143ff8c"
     ]
    },
    "id": "4LNLEvy_V3UC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5838e398-5905-4594-a389-938dd3a311ae"
   },
   "outputs": [],
   "source": [
    "distill_student(\n",
    "    base_weights_path=\"final_models/roberta_sentiment_exc4_weights.pt\",\n",
    "    teacher_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    student_name=\"distilroberta-base\",\n",
    "    output_dir=\"final_models/distilroberta_exc4-base\",\n",
    "    num_labels=5,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyJfmdT5V4Ih"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "d34e7da223274255b2ac28b8459963eb",
      "b4d0f131f48a400f8dd8cae161e9b7cb",
      "aa6571d7569c4d0d8958badaa0310e1e",
      "cd0f74a36ebb41a883f4bce4f17626d1",
      "2eeaf731471949ddbd0dd3c706860e1a",
      "41626344ae5144e9a017b48166c34d54",
      "bd9e5e2f043342348681e20df34da6e3",
      "cbf6bd3c5266445f929d13d8cd561b09",
      "bade3a86aba44fdc8155bd6e5f70f5de",
      "7f29f570b2c44e678483b5d5b35c5159",
      "bca02ef8bc48497e8f63b9d54cbba26b",
      "84fcb7a7def547909512b2250677f626",
      "19cc6f9ae43e485aa8f54201c9c4219f",
      "8f78870f66f443669545463c3972f89b",
      "3f69ea22fd3743d1a0c52ed87575dd95",
      "caf1b1e61e014576aeb2d0b041fc00ba",
      "cf69b2f97e4d420b82523f3cb0f019c3",
      "7868f2b574d34d8b909de42ee4b9b5ea",
      "a459fc4529bd420897c4d378de8fd24e",
      "f85bbeeea0834d8a86f0babcf4a4f45f",
      "a18d5af7eb1d4fccacc53ff0e8e25434",
      "1bd4614790514f70a47e60e21c5748df"
     ]
    },
    "id": "qs5OLBN09oZQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6b91431e-b081-46fa-a7cc-0d49c99776af"
   },
   "outputs": [],
   "source": [
    "student = distill_student(\n",
    "    base_weights_path=\"final_models/roberta_sentiment_weights.pt\",\n",
    "    teacher_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    student_name=\"distilroberta-base\",\n",
    "    output_dir=\"final_models/distilroberta-base\",\n",
    "    num_labels=5,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irXxRbzWvHqT"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "student Harsha901/tinybert-imdb-sentiment-analysis-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stWkC0o4WP6c"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645,
     "referenced_widgets": [
      "06a1d74e3f614cfe9464a9bf8f32be96",
      "18a7115677044e34bcca3bb4cac7c5be",
      "450e4291066e455db386109be5465fc8",
      "3cb775a86c36456ba33900e4b66ed14a",
      "f13c357f681f4521a356b634421aa92f",
      "6192dc4d93e14c13985283f0a269497f",
      "03d3b49904624e4e857ea8d70437b54c",
      "a54ec161d8014699a3affa4948e323cf",
      "77a1e5e5ccd041baa575321a0befad75",
      "b07af3c8b8324ac6b3be4d928b387eb9",
      "c7d828dad6af490baf3bfba26280a44c",
      "4191a55d782e49d789f15639ce165aca",
      "c4de0f922aa040a8bdc6acd9fab1dc9f",
      "f0d649404efb438abd61cc35310bc8e2",
      "7aacb34ea908497a81a968d166fbc3b7",
      "b6122e8763a043eb92a3a9ef9abecd75",
      "7c4e6db5eaac434a99defdab2c57fd95",
      "fe966f191955419597364c1e438c6bf9",
      "c7633bb3094a461eaa6d147750b2702d",
      "ff5c192ffd124e54a743ff3c79017618",
      "ff6eb4c923c24313b216789115b08a29",
      "55bdc244d42d464caadb09cf4e1c6ef8",
      "267efae75a7d4d00abf5eba6eaaa1d33",
      "6e017010dacb424f9a77597bb6972cf0",
      "b85162f9fbe04b8094f9b2ea78854671",
      "6c3c0f53b00240ffbce0c815e12fa57c",
      "a220967166604781b3dca800e3863ed0",
      "eb0f0e022f034424bd6703699c1418f5",
      "4be46bc914fd4c708e4f6fb5e0ca6411",
      "4fb6d2e56c03479aba25b31128e0a8e9",
      "0a6d37f8aa4a4a90b3bd0888be94a4fd",
      "b99bb48660f2496aa76bace20b5fb7ae",
      "fca7036c9ae84709af9a375f7e5cf6d3",
      "188104537ea74b81a902ccd4a1cc2ef7",
      "6e9c9e959b2d4fbaae0e681ba5a1a82e",
      "05327569d1d34bd59ee2a3fd796b31ca",
      "15a1aa70c45a430ea63d63c7dce7a89c",
      "5755235ca80c4d47911665a585b494e5",
      "413a0f9b9b0a467ca8c13fddde3fa98a",
      "fd65ac701a2349a99ac0ec6a42d20fbd",
      "0913880107d24e8c9b44f3aa1cc95ff9",
      "01d5b4e84ad04640a469ba2864751d0d",
      "7b503fa88e744628acb30a431154fddd",
      "37b30cf7ac80478ca91aa9e080978f23",
      "302f87be03d5447ead1ab4a3e550ccb7",
      "6c81e28ff21141a8a31db2e8efa56e84",
      "cc535b73752744a99c6a1fba8f1414cc",
      "26cb06f0a3f64b70bef4548b3f6ca766",
      "91c307c52b6b4899bf5e8af634fc10b3",
      "bd754acdffec41a1915c858b79349185",
      "9dd528352e1240db93cc67b9d288f7ac",
      "1c1fe083070d40618cd2043dc2ea6b8d",
      "bfa66a37c49843188aff9427f872743b",
      "6c0ab91ca1db46fe9236b234db017d4a",
      "921622e9dca944d9a303a730b741004d",
      "26a3164382dd4fa7ae65fc07ecdba37f",
      "9de8bc71421c46ba9874fe35ee6f8865",
      "42b024655c34466f803781ac8c6114a2",
      "e5bf765068294aa6b80f39ac96a5f558",
      "75c0ba7ca20c43aba2e89b15a5981c60",
      "09593c7a839c4cd59cc85f12acd12898",
      "72a88ade336746d5bb0cf4ace804caef",
      "1d57f31563bf48e796d7b29d10e21cfd",
      "a6b6f6bdbbb8424b8a76e14650bb328e",
      "ad5aa1677cf24a89addfce4415a1ab0d",
      "c2829c099b244f2798e022307f9a3767",
      "2e77d9d7663648f68d6c7dd4dace10e2",
      "f36f4c036b71437e9358912a212b5823",
      "83d4fdc742954a7c9ec0141e98847262",
      "fae3e618160b4ea9b595384048d46905",
      "505a2d8ae28d4e71aa02d918119dab6e",
      "7617a720074848af96e4fcdfa13f147e",
      "13b71dbe25c14bb6a1ee0754654837f2",
      "ce773d2d44a2426f9b1b7a1c3fbe787e",
      "edb44625f46645eb88003ead9a85c684",
      "3d58f1ff229340ca9460d42b10217e7e",
      "c8312cf1af874079a512537cb243f428",
      "4a61c233dd824b13b5049e9f6b75c462",
      "ac201fafa1b14bc5b83226d32d0a5066",
      "0955a2421b0d41c9a7d3ebeeefcb87c5",
      "580df5bc145f4cbbbedc0272d6ec7c62",
      "8efe2c2e59c44c98989e8d701f837243",
      "aa3fddec4c39450f9c2a484915eadf65",
      "283904ce772240aa8936d6bf8a9662f0",
      "0128a077756845ea944c42c8b6fbfd7c",
      "f900f90a5042470fb43565dcc74e5792",
      "c3cf6aff1b5d49fb8bab76d2d1e2bbcb",
      "224ebb1beb164916aefb1538bb3f567b"
     ]
    },
    "id": "CLN8akIPWPso",
    "outputId": "6653e9de-5c2b-4aeb-f290-98b07c4adb16"
   },
   "outputs": [],
   "source": [
    "student2 = distill_student(\n",
    "    base_weights_path=\"final_models/distilbert_exc4_weights.pt\",\n",
    "    teacher_name=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    student_name=\"Harsha901/tinybert-imdb-sentiment-analysis-model\",\n",
    "    output_dir=\"final_models/tinybert_exc4\",\n",
    "    num_labels=5,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC3VIYpIWPi3"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453,
     "referenced_widgets": [
      "4d0e7f008ab0443f89f43c47366bcf2e",
      "861669fc33ce4d1eb3969fb488340ab7",
      "b4e9175d9232491a8641dc3f445659e1",
      "8da53cbbe7da4e36afaacaf5b647e401",
      "e0cb98090d00404db52b9404f3f7c0ec",
      "2035f94f7a974c71b05e2e92a0a18249",
      "4e2e57da10604f0a8bc404959a143132",
      "a33a7f65adde475f993f282bab94b33a",
      "a932317479ba4fb4814255c3f51e87cd",
      "a15e2d5302a5486ab433f1b55cf57ec9",
      "6296c6eb0d794623947abaa4d1ea53f0",
      "8a8f8c4f2dce41cdb3b5fbe4e5fa3859",
      "978e150e55704e298c4ecdadb45ff24c",
      "4feacffc46cf47ed90931d3977ad753c",
      "3c14c071be944ad38258f2b579aa1961",
      "5f1cb6ccd9fc41719fb64f1547571bbc",
      "effefbae29624b558f145b8649b9553a",
      "22e96101c3c747cebf52c146a1a950be",
      "b981cfdea80d4baf8a9fb1d2994b83c9",
      "a9500de7017d46679a901abaa219dbb3",
      "836457a168784abebd830b04ad0c150b",
      "0e734bfa2a8b4cf8bcdf6db1e19088cd"
     ]
    },
    "id": "YK8zXr4FI0u0",
    "outputId": "45d683eb-4b6c-4b08-c09d-7f6679b8800e"
   },
   "outputs": [],
   "source": [
    "student2 = distill_student(\n",
    "    base_weights_path=\"final_models/distilbert_weights.pt\",\n",
    "    teacher_name=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    student_name=\"Harsha901/tinybert-imdb-sentiment-analysis-model\",\n",
    "    output_dir=\"final_models/tinybert\",\n",
    "    num_labels=5,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l79TuXEzqE3Y"
   },
   "source": [
    "<h2>Forth Compression Method: <u><b>Low-Rank Factorization using SVD</b></u>.</h2>\n",
    "\n",
    "`compress_model_low_rank`\n",
    "\n",
    "This function applies low-rank factorization using Singular Value Decomposition (SVD) to compress a transformer model. It focuses on compressing the weight matrices of Linear layers within the model, particularly within the attention and feed-forward components, by approximating them with lower-rank matrices derived from SVD. The compressed model is then saved along with its tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuUxuYARb7Rj"
   },
   "outputs": [],
   "source": [
    "def compress_model_low_rank(base_weights_path, save_model_path, model_name, rank=64):\n",
    "    \"\"\"\n",
    "    Apply low-rank SVD compression to transformer model and save it.\n",
    "    \"\"\"\n",
    "    # === Load pretrained model & tokenizer ===\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=5,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(\"✅ Model loaded successfully\")\n",
    "\n",
    "    # === Helper: Low-rank factorization ===\n",
    "    def low_rank_approximation_linear(layer: nn.Linear, rank: int):\n",
    "        W = layer.weight.data  # [out, in]\n",
    "        U, S, Vt = torch.linalg.svd(W, full_matrices=False)  # better numerics than torch.svd\n",
    "\n",
    "        U_r = U[:, :rank]      # [out, rank]\n",
    "        S_r = S[:rank]         # [rank]\n",
    "        Vt_r = Vt[:rank, :]    # [rank, in]\n",
    "\n",
    "        # First layer: in_features -> rank\n",
    "        first = nn.Linear(layer.in_features, rank, bias=False)\n",
    "        first.weight.data = Vt_r\n",
    "\n",
    "        # Second layer: rank -> out_features\n",
    "        second = nn.Linear(rank, layer.out_features, bias=True)\n",
    "        second.weight.data = (U_r * S_r).T\n",
    "\n",
    "        if layer.bias is not None:\n",
    "            second.bias.data = layer.bias.data.clone()\n",
    "\n",
    "        return nn.Sequential(first, second)\n",
    "\n",
    "    # === Apply compression ONLY to attention & feed-forward projections ===\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Skip classifier head (must remain unchanged)\n",
    "            if name.startswith(\"classifier\"):\n",
    "                continue\n",
    "            # Compress only square projections (768x768, 3072x768 etc.)\n",
    "            if module.in_features >= rank and module.out_features >= rank:\n",
    "                new_layer = low_rank_approximation_linear(module, rank)\n",
    "\n",
    "                parent = model\n",
    "                for attr in name.split(\".\")[:-1]:\n",
    "                    parent = getattr(parent, attr)\n",
    "                setattr(parent, name.split(\".\")[-1], new_layer)\n",
    "\n",
    "    # === Save compressed model (architecture + weights) ===\n",
    "    os.makedirs(save_model_path, exist_ok=True)\n",
    "    torch.save(model, os.path.join(save_model_path, \"model.pt\"))\n",
    "    tokenizer.save_pretrained(save_model_path)\n",
    "\n",
    "    print(f\"💾 Compressed model saved at: {save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVTEHkonuQoJ"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj0Ig6KCuXgv"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ggh7JcE7q-lJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b3e71414-9cd8-4830-ffec-7d7d97f492d0"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "save_model_path = \"final_models/roberta_sentiment_exc4_SVD\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "compress_model_low_rank(base_weights_path, save_model_path, model_name, rank=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z7wguU-unks"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tmKVMGNuqlL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d9ccd61e-93e4-4bb5-f1ba-1fb9e74bb86b"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_weights.pt\"\n",
    "save_model_path = \"final_models/roberta_sentiment_SVD\"\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "compress_model_low_rank(base_weights_path, save_model_path, model_name, rank=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETuRGm18u3ZV"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95Y4nzfius7W"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghP-cQdlutWp",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "651d5188-d3d2-4491-989e-84449bd3fb02"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_exc4_weights.pt\"\n",
    "save_model_path = \"final_models/distilbert_exc4_SVD\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "compress_model_low_rank(base_weights_path, save_model_path, model_name, rank=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O33hD0yDut6_"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isbsXLHCuPcc",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c0eaf9f2-d9f5-4268-c727-3fd98e1bf993"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_weights.pt\"\n",
    "save_model_path = \"final_models/distilbert_SVD\"\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "compress_model_low_rank(base_weights_path, save_model_path, model_name, rank=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feSxz90O77hA"
   },
   "source": [
    "<h2>Fifth Compression Method: <u><b>LoRA</b></u>.</h2>\n",
    "\n",
    "LoRA, or Low-Rank Adaptation, is a technique that freezes a large model's weights and only trains small, new matrices to adapt it for a specific task. We use it to drastically reduce the number of trainable parameters, making fine-tuning much faster and more memory-efficient. This results in a tiny, task-specific model that is quick to train and easy to store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlQ1d2UtEP3G"
   },
   "outputs": [],
   "source": [
    "# === Load CSV files ===\n",
    "drive_path = \"data/\"\n",
    "train_dataset = pd.read_csv(drive_path + \"train_balanced.csv\", encoding=\"ISO-8859-1\")\n",
    "eval_dataset = pd.read_csv(drive_path + \"val_clean.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Convert pandas → HF Dataset\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "eval_dataset = Dataset.from_pandas(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vzx5Gt5JOMr"
   },
   "source": [
    "`lora_training`\n",
    "\n",
    "This function sets up and runs the training process for a model with LoRA (Low-Rank Adaptation) adapters. It prepares the datasets, configures the HuggingFace TrainingArguments for training parameters, initializes a Trainer object with the LoRA-enabled model and data, and then starts the training. The function handles tokenization, data formatting, and uses the specified training arguments. After training, it returns the trained LoRA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gG9TVrfEGwQ"
   },
   "outputs": [],
   "source": [
    "def lora_training(model, tokenizer, train_dataset, eval_dataset, output_dir, num_epochs=3):\n",
    "    def preprocess(batch):\n",
    "        texts = [str(x) if x is not None else \"\" for x in batch[\"text\"]]\n",
    "        return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "    train_dataset_proc = train_dataset.map(preprocess, batched=True)\n",
    "    eval_dataset_proc = eval_dataset.map(preprocess, batched=True)\n",
    "\n",
    "    train_dataset_proc = train_dataset_proc.rename_column(\"label\", \"labels\")\n",
    "    eval_dataset_proc = eval_dataset_proc.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    train_dataset_proc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    eval_dataset_proc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-4,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=output_dir + \"/logs\",\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_proc,\n",
    "        eval_dataset=eval_dataset_proc,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paWbVy_UJnOv"
   },
   "source": [
    "`LoraModel`\n",
    "\n",
    "This function orchestrates the process of applying and training LoRA adapters on a base model, and then merging the trained adapters back into the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQvrxuy57tBN"
   },
   "outputs": [],
   "source": [
    "def LoraModel(model_name, base_weights_path, save_lora_path, model_type=\"roberta\", num_labels=5):\n",
    "    \"\"\"\n",
    "    Apply LoRA adapters to a pretrained model (Roberta / DistilBERT).\n",
    "\n",
    "    Args:\n",
    "        model_name (str): HuggingFace model name\n",
    "        base_weights_path (str): Path to fine-tuned base model weights\n",
    "        save_lora_path (str): Directory to save the trained LoRA model\n",
    "        model_type (str): \"roberta\" or \"distilbert\"\n",
    "        num_labels (int): Number of classification labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Load base model with correct number of labels\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=num_labels, ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # Load fine-tuned weights\n",
    "    state_dict = torch.load(base_weights_path, map_location=\"cpu\")\n",
    "    base_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Choose target_modules depending on model type\n",
    "    if model_type.lower() == \"roberta\":\n",
    "        target_modules = [\"query\", \"value\"]\n",
    "    elif model_type.lower() == \"distilbert\":\n",
    "        target_modules = [\"q_lin\", \"v_lin\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type '{model_type}'. Use 'roberta' or 'distilbert'.\")\n",
    "\n",
    "    # LoRA config\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        target_modules=target_modules,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )\n",
    "\n",
    "    # Apply LoRA adapters\n",
    "    lora_model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "    # === Train LoRA adapters ===\n",
    "    lora_model = lora_training(\n",
    "        model=lora_model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        output_dir=save_lora_path,\n",
    "        num_epochs=3\n",
    "    )\n",
    "    print(\"✅ LoRA training finished.\")\n",
    "\n",
    "    # Save tokenizer + model (before training, so you can reload later)\n",
    "    tokenizer.save_pretrained(save_lora_path)\n",
    "    lora_model.save_pretrained(save_lora_path)\n",
    "    print(\"✅ Trained LoRA model saved to:\", save_lora_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvLrzeHeCQyb"
   },
   "source": [
    "**First Model**\n",
    "\n",
    "twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBYmkvvQGEgM"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513,
     "referenced_widgets": [
      "c3d6c68beb6646df9d31a232f8a60a93",
      "78a89f692d1249309bc039cfb684acfb",
      "726b72ca060d4ba8871e56f15d1c86eb",
      "d39ea6085624431c84ed1b2987f9ce45",
      "0e24bb0037814c23826f3d57b28ab268",
      "bb2ca54a0427455bbd91bb0308a71c04",
      "d95d0aa0987c4fb49f85221545ac2442",
      "6a19ce858ff14c50b5fe056f346f0f76",
      "e2983c9309504876aae28feb0c9f3ba3",
      "b664fd631aa645058d9581f6d18d199f",
      "08d5de234e81454da3b65d80174aa801",
      "2bd56f42ecc64db0849003031cae41d1",
      "f4868f6520ec4f32b30657f92f92149b",
      "cffd5244b2ed4bd385826e828c7d4314",
      "267442fa61ed4e0e86178498591685ad",
      "393a990e61af4bcea8d5510963a8c7e6",
      "2db9412b06d844db9ae8ea96de173f89",
      "818e338e4617444b855d323b7d2b860d",
      "895fd151d26e429686330f6d93278bb7",
      "13a2b9fbd9da4170b62fdb0c174f517e",
      "9f4098010fa746f6962673f36bcd2537",
      "6797e1cd34634ce4a3f9576b14608882"
     ]
    },
    "id": "fpDC6oIiCQda",
    "outputId": "103b64d5-9007-455b-9262-99b5f8acc93b"
   },
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "base_weights_path = \"final_models/roberta_sentiment_exc4_weights.pt\"\n",
    "save_lora_path = \"final_models/roberta_sentiment_exc4_LoRA\"\n",
    "LoraModel(model_name, base_weights_path, save_lora_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_RBFXfOGGwT"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627,
     "referenced_widgets": [
      "8909ca54f92845d085895e59258fc3b3",
      "09592d51b28d4e0a94fc96ec470b4677",
      "d5a527d14dd144b78d27db1d14335cbd",
      "1032c19117854fcb9542f5f1eb935be4",
      "3f2a4e9165b0482bbb9c4f9425442170",
      "4a7e507f1e874cd7b7fe48434e9aed2a",
      "03585d3148cd4e04b14fb672678ab331",
      "f34958d4af4748e1a8344be48fac7615",
      "7eb223e6b4684a9b835bfdb7abadcdfa",
      "9c33ad6affc149b190ea92a7ca6c116f",
      "bd503b3f0a0c4f3cb433b7a1ae1d666c",
      "c1b60e9d452d495aa89214b6411508fe",
      "efd2d77f3a554086811a6e85e7fec554",
      "d2c941f947c04f65b49cece93a56aa7c",
      "37eea1f87ba24ec7b50a907fc9434f90",
      "9df5c94282594b218861a5cd09f5e9dc",
      "ba19178fe721455cbee70cfd1b9745b6",
      "6b0e3ccbbd12468bbb7ccd0fa7ecee04",
      "678ec12c93454a6f9ffb2ec8f7a8aa68",
      "20220c4ec03f44309d83d16dd804cba7",
      "ae7c867a5f8f4bbcae9778aa7c12f59c",
      "c25f735f8e374940837dbe2b9ee5c8dd",
      "f0abc448b6b74f89b2bde1873c5e85dc",
      "beaaa3e4d480404dad55e346915dd859",
      "27540fd47701447683d71f5028726ddf",
      "4a40cff4ff614980b1be064ec36f596e",
      "a6887f08101f43caac651b3ca3a0b29c",
      "f0087afdc0984c69875e98ea6a27c31d",
      "ffc01715bdd142b0b451e61af95e92b3",
      "6b8ba349a54d4d07b78d55ae17e32e72",
      "8e069ae65aeb4bdda65ecee7eafe2b3c",
      "5869ebda3cff4b5f9bd3eea2910a3925",
      "f9625ff73bb64f8ab88d8e97ace38f7c",
      "54180f9cf6ba45adb1782aebdb337714",
      "f766af8dd26f477b8ad7e02f8d59c5b5",
      "54ee2840a134411b814a97182e7cc3ac",
      "82bc527d25de4f78b212bbac9aae3b0b",
      "a497fb5cdd2d4455afaf142d584b91b7",
      "b1766121f36b4dac95ca79146db5f345",
      "2709dc0e74e6422dbf234dda70a5c348",
      "bf7c393ae8234237aa2132c382f4564b",
      "a6dbec2f086c411ba1c4f9a9885bb5cc",
      "ddd9d0a195674b498eb585880d6fbf80",
      "98bb7c702eb94f11ad3c0021f6b9234c",
      "bff24096107143c483f71dae165a7009",
      "1399b93c46d44908abe45da460d10bd3",
      "d3cb4f86a055485488740546160e8858",
      "c7965c4291f84bffbfe5418bf25a5636",
      "58c3f5015758495ea32735762af10cef",
      "ed6298e979c34c049f5e6397a737b59f",
      "b2126963cc6341fe99c1599b6bee6c5c",
      "9498db80122842aca6f8996da426acd2",
      "dc376aa7744e462796516f467384f1ba",
      "6cc64c4359bd4ce2af53c1d3efd9d09e",
      "add5402b49544a7cb27ab008524b2492",
      "5fbb162b8d064ce383b2e1d338291b68",
      "12835bee8aee4ec78973a17ed55783ac",
      "238ca5382d4d40f6ad9f725f9bd993e9",
      "2ba921d8371c452294b41f1ef2c1f433",
      "dd7ea2b7860444f897c25fe18ef9501e",
      "059171d5c51a407f82656cf22a7c08ca",
      "b9fa19757eaf4165b6e7f618f7617e99",
      "e6ff0ce42ba94e408f35efbd916e5e8b",
      "611698d10d204a078d9bdd15ada4c9bb",
      "e493253db3994cd68a3ee5aa0f4e02b3",
      "ce6ddf416c5c400ab73788877c1129aa",
      "5a20ae6726bd4c17b2ff92b103eb43b4",
      "90b18889f9e0400881975ed5889bd321",
      "722594d46df44fc1ba40608f65f9fb7b",
      "ce81e96d82e448b4b01b51e0ce972e68",
      "0bcaff4bf7944bf1afaa72361a868df3",
      "3b75e781595343cf908022aac52d23be",
      "7c55061eb9ce42cf89aefdcf09552db7",
      "312f3f7c42b24f7a8887b7b8d6b56540",
      "81f3144707d44920bf75de85061ce1a5",
      "77a50c513b294e01862c810514c73c45",
      "bfa9cfc245bb42f981a28e489b96f2bf",
      "f4f821d0325641a580ae07e2516637ef",
      "64c097cc8a1f4f608850741556e34d3d",
      "fff255fd81f14222a9f4703538d52bc7",
      "7064f213e7f84c3a98db5081d825150f",
      "79d9e0c77e144e7d92899ae6e7d82461",
      "4e812720f3f3483a8a3204deff7020fe",
      "44a91a10d7b54aa98bc970be844e88cd",
      "4fa811e172734bf087c575a19c77fb7f",
      "a2e31ed58c3545509bd09937f99d2895",
      "7aaed77e13ba40edafb9e969ff4c257a",
      "35c6d17aa1e346c28915b539991b7f8e"
     ]
    },
    "id": "HPkUCqopGGdM",
    "outputId": "52944cc5-13eb-4234-bd96-baf583d33b6f"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/roberta_sentiment_weights.pt\"\n",
    "save_lora_path = \"final_models/roberta_sentiment_exc5_LoRA\"\n",
    "LoraModel(model_name, base_weights_path, save_lora_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugugGN1xCROO"
   },
   "source": [
    "**Second Model**\n",
    "\n",
    "distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4A_cCllaGLq0"
   },
   "source": [
    "From excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "ce087db0618546e78e0ff794f1c651a7",
      "abc435fa9b304b43a1611f0b382cbb40",
      "63c8e2c9d25842d6ac52e9996784d8c4",
      "217c2d4f031a4be680c039d13b3a7c78",
      "22c9f5e44c5445afb084e0c3cba99acf",
      "2f987f07aa7a4b7587fdaa55a08e9d6b",
      "5d770911b8474d309a049e2e431876ce",
      "fff6283f4be5472782245cb886888f2a",
      "65909da20d744152a2fa10766dbcd90d",
      "0a796f8b8f634ff2a9938fa918467a8f",
      "5bdfa45351c84cdc8d15e836c6c570bf",
      "3bec9c4a1a9b4a07bdde0a32acdfff39",
      "7e20caba938d4448921750742fccb68c",
      "3866f5a78cc54e9ab0dbf7b46167d0ce",
      "45f2fac500364d809253b3170cdbc0c4",
      "a05ee76800054d058c49c2ffdca9caa4",
      "902281d3e5d340b9a8600bf213728749",
      "6be546a2b75e4473b4f4557ce2a0b7e9",
      "5c2197b3a9a74411b828c067748fac03",
      "53b1ec0e8cdf4423a92209663822c9b6",
      "0674b7c5d776472b8740aaeec5cea823",
      "3c67968a061740a9a7edb0e1f34c6cbc"
     ]
    },
    "id": "CjxAZN9jCRnG",
    "outputId": "b0cecd5c-09d2-4d9f-de24-865d9e138f5d"
   },
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "base_weights_path = \"final_models/distilbert_exc4_weights.pt\"\n",
    "save_lora_path = \"final_models/distilbert_exc4_LoRA\"\n",
    "LoraModel(model_name, base_weights_path, save_lora_path, model_type = \"distilbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuzuiSVUGMrw"
   },
   "source": [
    "From excercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "0126901f88404b52b313eefc86891a61",
      "564c769f114e45e49aa931d9c7cdc8a2",
      "1c630d71516a4f7bb1c8342c355b819e",
      "1985983280e746738b9a6df5fa62787e",
      "4580d0bc756648d9a149259ed49b2cab",
      "22de4f3547a54c9e84cff3523a01aff0",
      "6fd217e92cac4520a86ffc0a497c36e2",
      "64d7ce1c7fc8471d834b0bcf835ef29b",
      "4f47a92eb885461c84e86f6ef0739f18",
      "75ca3681ab6c41139f42677485eec6c8",
      "c8448c5caf80452ba4fb9dc2e0e8f301",
      "81515c650bc64da88687d8031cfbfd18",
      "16821e3bfaf54ecdaf67e75c5501b03a",
      "321f1f0bf768419496a86449715f00de",
      "a905194a98d145f2a34daa4cab33e6ff",
      "60d1af1bc16345008a8cb02b31c77e1c",
      "427fa27b30774b088afdceb670d8d640",
      "d069bf3e02974a8a87b34d0dc66e2b43",
      "7d93db6f14c74169841f94c104cd78c9",
      "d07367194dba48e2876b8959d0d11820",
      "4005a2b8b51f4405889e0f500448d4f4",
      "9887a65c7ea64606a531b4ae3749a8d1"
     ]
    },
    "id": "61X255lGGOYp",
    "outputId": "b2c47d2b-17a1-4c46-cd4b-8cf83016b3ff"
   },
   "outputs": [],
   "source": [
    "base_weights_path = \"final_models/distilbert_weights.pt\"\n",
    "save_lora_path = \"final_models/distilbert_exc5_LoRA\"\n",
    "LoraModel(model_name, base_weights_path, save_lora_path, model_type = \"distilbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNoXd3Zw8zmj"
   },
   "source": [
    "<center><h1>END</h1></center>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
